{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Predictive Analytics\n",
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Troy Zhongyi Zhang      \n",
    "Netid: zhongyiz@uchicago.edu   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ProviderInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['PHONE','COUNTY_SSA'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15617, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 - a.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.replace(['NaT'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14557, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 - b.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.model_selection as cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 1 - c.\n",
    "y = df.iloc[:,3]\n",
    "X = df.loc[:, list(df.columns[0:3]) + list(df.columns[4:])]\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - d.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaler.fit(X_test)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11645, 27)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2912, 27)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11645, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2912, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhongyizhang/env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/zhongyizhang/env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/zhongyizhang/env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/zhongyizhang/env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5., 4., 4., ..., 3., 4., 5.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train_scaled, y_train)\n",
    "log_y_pred = clf.predict(X_test_scaled)\n",
    "log_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.39345625e-07, 6.52421115e-02, 1.06378048e-01, 2.38235431e-01,\n",
       "        5.90144069e-01],\n",
       "       [9.27532789e-03, 4.08359774e-02, 4.36890747e-01, 5.12997602e-01,\n",
       "        3.45554729e-07],\n",
       "       [1.31932902e-02, 4.92778313e-02, 4.58601777e-01, 4.78926231e-01,\n",
       "        8.70240514e-07],\n",
       "       ...,\n",
       "       [2.25577356e-01, 8.88049794e-02, 3.72986528e-01, 3.12631134e-01,\n",
       "        2.53210869e-09],\n",
       "       [1.17742501e-03, 2.24640816e-01, 3.47969652e-01, 4.26029943e-01,\n",
       "        1.82163298e-04],\n",
       "       [5.23177208e-07, 5.52820267e-02, 1.31582856e-01, 2.25585337e-01,\n",
       "        5.87549257e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = clf.predict_proba(X_test_scaled) \n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression training set accuracy score: 70.62 %\n",
      "Logistic regression testing set accuracy score: 68.72 %\n"
     ]
    }
   ],
   "source": [
    "acc_log = round(clf.score(X_train_scaled, y_train) * 100, 2)\n",
    "acc_log_test = round(clf.score(X_test_scaled, y_test) * 100, 2)\n",
    "print('Logistic regression training set accuracy score:',acc_log,'%')\n",
    "print('Logistic regression testing set accuracy score:',acc_log_test,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[244,  64,   0,   0,   0],\n",
       "       [ 61, 411,  93,  11,   0],\n",
       "       [  0, 203,  58, 237,   0],\n",
       "       [  0,  87,  22, 486,  99],\n",
       "       [  0,   0,   0,  34, 802]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, log_y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "OVERALL_RATING 1       0.80      0.79      0.80       308\n",
      "OVERALL_RATING 2       0.54      0.71      0.61       576\n",
      "OVERALL_RATING 3       0.34      0.12      0.17       498\n",
      "OVERALL_RATING 4       0.63      0.70      0.66       694\n",
      "OVERALL_RATING 5       0.89      0.96      0.92       836\n",
      "\n",
      "        accuracy                           0.69      2912\n",
      "       macro avg       0.64      0.66      0.63      2912\n",
      "    weighted avg       0.65      0.69      0.66      2912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['OVERALL_RATING 1', 'OVERALL_RATING 2', 'OVERALL_RATING 3', 'OVERALL_RATING 4', 'OVERALL_RATING 5']\n",
    "print(\"\", classification_report(y_test, log_y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - (d). Based on the confusion matrix and classification report, I found that the prediction for overall_rating score 3.0 class is very poor. The rating 3's accuracy scores are much lower than other overall_rating scores' predictions accuracies. According to the confusion matrix, there are not a lot of actual score 3s in the dataset, but the logistic regression model predicted them as 2 points or 4 points as the result. I will make an academic guess for the reason. I believe the 3 is the middle score in the range of score 1 through 5. It could be unlikely for a classification model to give prediction rating results just under the middle score \"3 points\" when the model felt vague in predictions. If the features show that the result prediction may tend to be a little bit lower than 3, the model will very likely to classify as 2 points. Conversely, if the features show that the result prediction may tend to be a little bit over 3 points, the model will likely to classify them as 4 points. There are many mistakes produced through here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 4., ..., 2., 5., 3.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_y_pred_t = clf.predict(X_train_scaled)\n",
    "log_y_pred_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.46665814e-03, 3.28179534e-01, 3.19369312e-01, 3.46980985e-01,\n",
       "        3.51051508e-06],\n",
       "       [1.29086540e-07, 1.34224143e-02, 1.02080810e-01, 2.08365372e-01,\n",
       "        6.76131274e-01],\n",
       "       [1.14947713e-04, 1.49932220e-01, 3.81279516e-01, 4.62773682e-01,\n",
       "        5.89963433e-03],\n",
       "       ...,\n",
       "       [3.72620454e-01, 3.90956027e-01, 1.55836941e-01, 8.05865773e-02,\n",
       "        1.25353084e-09],\n",
       "       [4.69509179e-09, 1.09236108e-02, 4.25712536e-02, 2.04567706e-01,\n",
       "        7.41937424e-01],\n",
       "       [1.83825077e-01, 2.27641943e-01, 3.25533126e-01, 2.62999850e-01,\n",
       "        4.01350426e-09]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_t = clf.predict_proba(X_train_scaled) \n",
    "prob_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression training set accuracy score: 70.62 %\n"
     ]
    }
   ],
   "source": [
    "acc_log = round(clf.score(X_train_scaled, y_train) * 100, 2)\n",
    "print('Logistic regression training set accuracy score:',acc_log,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - e. \"Training error is small and test error is big\" is an indication of overfitting. The training set accuracy score is 70.62 % and the testing set accuracy score is 68.72 %. It means that the testing RMSE is bigger than the Training RMSE. However, the RMSE values for training set and testing set are almost similar. It indicates that this logistic regression model is a little bit over-fitting or fits just well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1102,  287,    2,    0,    0],\n",
       "       [ 262, 1666,  343,   51,    0],\n",
       "       [   0,  737,  328,  830,    0],\n",
       "       [   0,  372,   43, 1798,  411],\n",
       "       [   0,    0,    0,   83, 3330]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix_t = metrics.confusion_matrix(y_train, log_y_pred_t)\n",
    "cnf_matrix_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "OVERALL_RATING 1       0.81      0.79      0.80      1391\n",
      "OVERALL_RATING 2       0.54      0.72      0.62      2322\n",
      "OVERALL_RATING 3       0.46      0.17      0.25      1895\n",
      "OVERALL_RATING 4       0.65      0.69      0.67      2624\n",
      "OVERALL_RATING 5       0.89      0.98      0.93      3413\n",
      "\n",
      "        accuracy                           0.71     11645\n",
      "       macro avg       0.67      0.67      0.65     11645\n",
      "    weighted avg       0.69      0.71      0.68     11645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['OVERALL_RATING 1', 'OVERALL_RATING 2', 'OVERALL_RATING 3', 'OVERALL_RATING 4', 'OVERALL_RATING 5']\n",
    "print(\"\", classification_report(y_train, log_y_pred_t, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.46665814e-03, 3.28179534e-01, 3.19369312e-01, 3.46980985e-01,\n",
       "        3.51051508e-06],\n",
       "       [1.29086540e-07, 1.34224143e-02, 1.02080810e-01, 2.08365372e-01,\n",
       "        6.76131274e-01],\n",
       "       [1.14947713e-04, 1.49932220e-01, 3.81279516e-01, 4.62773682e-01,\n",
       "        5.89963433e-03],\n",
       "       ...,\n",
       "       [3.72620454e-01, 3.90956027e-01, 1.55836941e-01, 8.05865773e-02,\n",
       "        1.25353084e-09],\n",
       "       [4.69509179e-09, 1.09236108e-02, 4.25712536e-02, 2.04567706e-01,\n",
       "        7.41937424e-01],\n",
       "       [1.83825077e-01, 2.27641943e-01, 3.25533126e-01, 2.62999850e-01,\n",
       "        4.01350426e-09]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict_proba for training set\n",
    "log_pred_prob = clf.predict_proba(X_train_scaled)\n",
    "log_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.39345625e-07, 6.52421115e-02, 1.06378048e-01, 2.38235431e-01,\n",
       "        5.90144069e-01],\n",
       "       [9.27532789e-03, 4.08359774e-02, 4.36890747e-01, 5.12997602e-01,\n",
       "        3.45554729e-07],\n",
       "       [1.31932902e-02, 4.92778313e-02, 4.58601777e-01, 4.78926231e-01,\n",
       "        8.70240514e-07],\n",
       "       ...,\n",
       "       [2.25577356e-01, 8.88049794e-02, 3.72986528e-01, 3.12631134e-01,\n",
       "        2.53210869e-09],\n",
       "       [1.17742501e-03, 2.24640816e-01, 3.47969652e-01, 4.26029943e-01,\n",
       "        1.82163298e-04],\n",
       "       [5.23177208e-07, 5.52820267e-02, 1.31582856e-01, 2.25585337e-01,\n",
       "        5.87549257e-01]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict_proba for testing set\n",
    "log_pred_prob = clf.predict_proba(X_test_scaled)\n",
    "log_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - PCA(n_components = 2) + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components=2)\n",
    "#X_2 = pca.fit(X_train_scaled)  \n",
    "#X_2_t = pca.fit(X_test_scaled)\n",
    "#print(X_2.explained_variance_ratio_) \n",
    "#print(X_2_t.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_2=X_2.transform(X_train_scaled)\n",
    "#X_2_t = X_2_t.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_2_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clfff = LogisticRegression(random_state=0,solver='lbfgs').fit(X_2, y_train)\n",
    "#y_pred_pcaaa = clfff.predict(X_2_t)\n",
    "#y_pred_pcaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnf_pcaaa = metrics.confusion_matrix(y_test, y_pred_pcaaa)\n",
    "#cnf_pcaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21505181 0.14512196]\n",
      "[0.23332873 0.15266908]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def fit_pca(df, n_components):\n",
    "    pca = PCA(n_components)\n",
    "    pca.fit(df)   \n",
    "    return pca\n",
    "pca_train = fit_pca(X_train_scaled, n_components=2)\n",
    "print(pca_train.explained_variance_ratio_) \n",
    "pca_test = fit_pca(X_test_scaled, n_components=2)\n",
    "print(pca_test.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  Projected dimension\n",
      "------------------------------\n",
      "21.5%:    -0.02 * f1 + -0.14 * f2 + -0.12 * f3 +  0.16 * f4 +  0.05 * f5 +  0.28 * f6 +  0.24 * f7 +  0.26 * f8 +  0.07 * f9 +  0.30 * f10\n",
      "14.5%:    -0.06 * f1 +  0.08 * f2 +  0.09 * f3 +  0.03 * f4 +  0.04 * f5 + -0.22 * f6 + -0.17 * f7 + -0.16 * f8 +  0.22 * f9 +  0.01 * f10\n"
     ]
    }
   ],
   "source": [
    "vars = pca_train.explained_variance_ratio_\n",
    "c_names = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10']\n",
    "\n",
    "print('Variance:  Projected dimension')\n",
    "print('------------------------------')\n",
    "for idx, row in enumerate(pca_train.components_):\n",
    "    output = '{0:4.1f}%:    '.format(100.0 * vars[idx])\n",
    "    output += \" + \".join(\"{0:5.2f} * {1:s}\".format(val, name) for val, name in zip(row, c_names))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  Projected dimension\n",
      "------------------------------\n",
      "23.3%:    -0.00 * f1 + -0.13 * f2 + -0.11 * f3 +  0.14 * f4 +  0.03 * f5 +  0.30 * f6 +  0.25 * f7 +  0.29 * f8 +  0.00 * f9 +  0.33 * f10\n",
      "15.3%:    -0.06 * f1 +  0.07 * f2 +  0.07 * f3 +  0.00 * f4 +  0.05 * f5 + -0.15 * f6 + -0.12 * f7 + -0.10 * f8 +  0.23 * f9 +  0.07 * f10\n"
     ]
    }
   ],
   "source": [
    "vars = pca_test.explained_variance_ratio_\n",
    "c_names = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10']\n",
    "\n",
    "print('Variance:  Projected dimension')\n",
    "print('------------------------------')\n",
    "for idx, row in enumerate(pca_test.components_):\n",
    "    output = '{0:4.1f}%:    '.format(100.0 * vars[idx])\n",
    "    output += \" + \".join(\"{0:5.2f} * {1:s}\".format(val, name) for val, name in zip(row, c_names))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_2 = pca_train.transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.26369816,  0.30603356],\n",
       "       [ 0.32175768,  2.41909625],\n",
       "       [-0.09147553,  0.48564829],\n",
       "       ...,\n",
       "       [-0.91500033, -1.0780606 ],\n",
       "       [ 1.97518127, -0.17351481],\n",
       "       [-1.03941956, -2.14167152]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11645, 27)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11645, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_2 = pca_test.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2912, 27)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2912, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhongyizhang/env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/zhongyizhang/env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5., 2., 1., ..., 2., 2., 5.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfp2 = LogisticRegression(random_state=0,solver='lbfgs').fit(X_train_pca_2, y_train)\n",
    "y_pred_pca2 = clfp2.predict(X_test_pca_2)\n",
    "y_pred_pca2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression training set accuracy score for n = 2 PCA: 39.68 %\n",
      "Logistic regression testing set accuracy score for n = 2 PCA: 37.19 %\n"
     ]
    }
   ],
   "source": [
    "pca_2_train = round(clfp2.score(X_train_pca_2, y_train) * 100, 2)\n",
    "pca_2_test = round(clfp2.score(X_test_pca_2, y_test) * 100, 2)\n",
    "print('Logistic regression training set accuracy score for n = 2 PCA:',pca_2_train,'%')\n",
    "print('Logistic regression testing set accuracy score for n = 2 PCA:',pca_2_test,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[117, 167,   0,   4,  20],\n",
       "       [106, 244,   0,  11, 215],\n",
       "       [ 45, 195,   2,  16, 240],\n",
       "       [ 30, 172,   2,  23, 467],\n",
       "       [  7, 120,   0,  12, 697]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_pca2 = metrics.confusion_matrix(y_test, y_pred_pca2)\n",
    "cnf_pca2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "OVERALL_RATING 1       0.38      0.38      0.38       308\n",
      "OVERALL_RATING 2       0.27      0.42      0.33       576\n",
      "OVERALL_RATING 3       0.50      0.00      0.01       498\n",
      "OVERALL_RATING 4       0.35      0.03      0.06       694\n",
      "OVERALL_RATING 5       0.43      0.83      0.56       836\n",
      "\n",
      "        accuracy                           0.37      2912\n",
      "       macro avg       0.39      0.33      0.27      2912\n",
      "    weighted avg       0.38      0.37      0.28      2912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['OVERALL_RATING 1', 'OVERALL_RATING 2', 'OVERALL_RATING 3', 'OVERALL_RATING 4', 'OVERALL_RATING 5']\n",
    "print(\"\", classification_report(y_test, y_pred_pca2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set after PCA when n_components = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., ..., 2., 5., 2.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_pca2_tr = clfp2.predict(X_train_pca_2)\n",
    "y_pred_pca2_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression training set accuracy score for n = 2 PCA: 39.68 %\n"
     ]
    }
   ],
   "source": [
    "pca_2_train = round(clfp2.score(X_train_pca_2, y_train) * 100, 2)\n",
    "print('Logistic regression training set accuracy score for n = 2 PCA:',pca_2_train,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - d. \"Training error is small and test error is big\" is an indication of overfitting. The training set accuracy score is 39.68 % and the testing set accuracy score is 37.19 %. It means that the testing RMSE is a little bit bigger than the Training RMSE. However, the training RMSE and the testing RMSE are still very close. This indicates that the logistic regression model after n_components=2 PCA is a little bit tiny over-fitting, but it is not a good model since the overall accuracies are too low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 571,  630,    6,   30,  154],\n",
       "       [ 405, 1045,    8,   49,  815],\n",
       "       [ 153,  781,    6,   48,  907],\n",
       "       [  81,  580,    4,   76, 1883],\n",
       "       [  32,  390,    6,   62, 2923]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_pca2_tr = metrics.confusion_matrix(y_train, y_pred_pca2_tr)\n",
    "cnf_pca2_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "OVERALL_RATING 1       0.46      0.41      0.43      1391\n",
      "OVERALL_RATING 2       0.31      0.45      0.36      2322\n",
      "OVERALL_RATING 3       0.20      0.00      0.01      1895\n",
      "OVERALL_RATING 4       0.29      0.03      0.05      2624\n",
      "OVERALL_RATING 5       0.44      0.86      0.58      3413\n",
      "\n",
      "        accuracy                           0.40     11645\n",
      "       macro avg       0.34      0.35      0.29     11645\n",
      "    weighted avg       0.34      0.40      0.31     11645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['OVERALL_RATING 1', 'OVERALL_RATING 2', 'OVERALL_RATING 3', 'OVERALL_RATING 4', 'OVERALL_RATING 5']\n",
    "print(\"\", classification_report(y_train, y_pred_pca2_tr, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - e. The overall accuracies for this model 2 (n_components = 2 PCA) are much poorer than the performance of model one without PCA. The reason for this is PCA filters the most important features by calculating the variances of each feature. However, n_components=2 means this PCA model only keeps 2 most crucial features with the highest variances. 2 features are still too less and not enough for an accurate model. The accuracy scores will decrease compared with the original model, model 1, which keeps all the features included without any filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - PCA(n_components = 16) + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21505181 0.14512196 0.13276604 0.09318017 0.06820902 0.05709726\n",
      " 0.04573236 0.03657319 0.03318498 0.03032689 0.02730018 0.02661403\n",
      " 0.02277657 0.02144951 0.01688691 0.01473191]\n",
      "[0.23332873 0.15266908 0.11817156 0.10078873 0.07340774 0.04365011\n",
      " 0.04057384 0.0375469  0.03183784 0.02777157 0.02635936 0.02331455\n",
      " 0.0225213  0.02115547 0.01817375 0.01589198]\n"
     ]
    }
   ],
   "source": [
    "def fit_pca(df, n_components):\n",
    "    pca = PCA(n_components)\n",
    "    pca.fit(df)   \n",
    "    return pca\n",
    "pca_train2 = fit_pca(X_train_scaled, n_components=16)\n",
    "print(pca_train2.explained_variance_ratio_) \n",
    "pca_test2 = fit_pca(X_test_scaled, n_components=16)\n",
    "print(pca_test2.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  Projected dimension\n",
      "------------------------------\n",
      "21.5%:    -0.02 * f1 + -0.14 * f2 + -0.12 * f3 +  0.16 * f4 +  0.05 * f5 +  0.28 * f6 +  0.24 * f7 +  0.26 * f8 +  0.07 * f9 +  0.30 * f10\n",
      "14.5%:    -0.06 * f1 +  0.08 * f2 +  0.09 * f3 +  0.03 * f4 +  0.04 * f5 + -0.22 * f6 + -0.17 * f7 + -0.16 * f8 +  0.22 * f9 +  0.01 * f10\n",
      "13.3%:     0.08 * f1 +  0.03 * f2 +  0.00 * f3 + -0.25 * f4 + -0.09 * f5 +  0.05 * f6 + -0.00 * f7 +  0.08 * f8 +  0.15 * f9 +  0.07 * f10\n",
      " 9.3%:     0.14 * f1 + -0.01 * f2 + -0.02 * f3 +  0.01 * f4 + -0.06 * f5 + -0.07 * f6 + -0.30 * f7 +  0.17 * f8 +  0.48 * f9 + -0.26 * f10\n",
      " 6.8%:    -0.24 * f1 +  0.60 * f2 +  0.60 * f3 + -0.03 * f4 +  0.15 * f5 +  0.13 * f6 +  0.10 * f7 +  0.14 * f8 +  0.01 * f9 + -0.02 * f10\n",
      " 5.7%:     0.29 * f1 + -0.14 * f2 + -0.13 * f3 +  0.08 * f4 +  0.07 * f5 + -0.04 * f6 + -0.02 * f7 + -0.07 * f8 + -0.01 * f9 +  0.02 * f10\n",
      " 4.6%:    -0.30 * f1 +  0.04 * f2 +  0.02 * f3 + -0.08 * f4 + -0.11 * f5 +  0.09 * f6 +  0.16 * f7 + -0.47 * f8 +  0.25 * f9 +  0.16 * f10\n",
      " 3.7%:    -0.03 * f1 + -0.14 * f2 + -0.10 * f3 +  0.24 * f4 +  0.76 * f5 +  0.10 * f6 +  0.11 * f7 + -0.03 * f8 +  0.12 * f9 + -0.13 * f10\n",
      " 3.3%:    -0.40 * f1 + -0.22 * f2 + -0.17 * f3 + -0.12 * f4 + -0.38 * f5 +  0.08 * f6 +  0.12 * f7 +  0.10 * f8 +  0.02 * f9 + -0.11 * f10\n",
      " 3.0%:     0.17 * f1 +  0.12 * f2 +  0.10 * f3 +  0.16 * f4 + -0.08 * f5 + -0.13 * f6 + -0.19 * f7 +  0.01 * f8 + -0.08 * f9 +  0.06 * f10\n",
      " 2.7%:    -0.25 * f1 +  0.02 * f2 +  0.05 * f3 +  0.59 * f4 + -0.29 * f5 + -0.06 * f6 + -0.05 * f7 +  0.01 * f8 +  0.00 * f9 + -0.02 * f10\n",
      " 2.7%:    -0.44 * f1 + -0.11 * f2 + -0.05 * f3 + -0.14 * f4 +  0.03 * f5 + -0.06 * f6 + -0.14 * f7 +  0.16 * f8 + -0.02 * f9 + -0.17 * f10\n",
      " 2.3%:    -0.26 * f1 + -0.13 * f2 + -0.10 * f3 + -0.31 * f4 +  0.20 * f5 +  0.02 * f6 +  0.01 * f7 +  0.06 * f8 + -0.00 * f9 + -0.03 * f10\n",
      " 2.1%:     0.41 * f1 +  0.09 * f2 +  0.04 * f3 +  0.08 * f4 + -0.29 * f5 +  0.25 * f6 +  0.26 * f7 +  0.01 * f8 +  0.08 * f9 + -0.18 * f10\n",
      " 1.7%:    -0.21 * f1 + -0.06 * f2 + -0.06 * f3 +  0.57 * f4 +  0.02 * f5 + -0.07 * f6 + -0.06 * f7 +  0.02 * f8 + -0.00 * f9 +  0.01 * f10\n",
      " 1.5%:     0.01 * f1 +  0.02 * f2 +  0.00 * f3 + -0.09 * f4 +  0.03 * f5 + -0.50 * f6 + -0.38 * f7 +  0.04 * f8 + -0.08 * f9 +  0.23 * f10\n"
     ]
    }
   ],
   "source": [
    "vars = pca_train2.explained_variance_ratio_\n",
    "c_names = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10']\n",
    "\n",
    "print('Variance:  Projected dimension')\n",
    "print('------------------------------')\n",
    "for idx, row in enumerate(pca_train2.components_):\n",
    "    output = '{0:4.1f}%:    '.format(100.0 * vars[idx])\n",
    "    output += \" + \".join(\"{0:5.2f} * {1:s}\".format(val, name) for val, name in zip(row, c_names))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  Projected dimension\n",
      "------------------------------\n",
      "23.3%:    -0.00 * f1 + -0.13 * f2 + -0.11 * f3 +  0.14 * f4 +  0.03 * f5 +  0.30 * f6 +  0.25 * f7 +  0.29 * f8 +  0.00 * f9 +  0.33 * f10\n",
      "15.3%:    -0.06 * f1 +  0.07 * f2 +  0.07 * f3 +  0.00 * f4 +  0.05 * f5 + -0.15 * f6 + -0.12 * f7 + -0.10 * f8 +  0.23 * f9 +  0.07 * f10\n",
      "11.8%:     0.11 * f1 +  0.05 * f2 +  0.01 * f3 + -0.30 * f4 + -0.10 * f5 +  0.05 * f6 + -0.02 * f7 +  0.12 * f8 +  0.11 * f9 +  0.03 * f10\n",
      "10.1%:     0.13 * f1 + -0.04 * f2 + -0.06 * f3 +  0.05 * f4 + -0.07 * f5 + -0.07 * f6 + -0.30 * f7 +  0.19 * f8 +  0.47 * f9 + -0.26 * f10\n",
      " 7.3%:    -0.24 * f1 +  0.61 * f2 +  0.63 * f3 + -0.07 * f4 +  0.11 * f5 +  0.15 * f6 +  0.11 * f7 +  0.15 * f8 +  0.03 * f9 + -0.04 * f10\n",
      " 4.4%:     0.61 * f1 +  0.06 * f2 +  0.04 * f3 +  0.00 * f4 +  0.15 * f5 + -0.10 * f6 + -0.13 * f7 +  0.16 * f8 + -0.16 * f9 + -0.01 * f10\n",
      " 4.1%:    -0.05 * f1 +  0.08 * f2 +  0.03 * f3 + -0.16 * f4 + -0.37 * f5 +  0.02 * f6 +  0.05 * f7 + -0.36 * f8 +  0.16 * f9 +  0.19 * f10\n",
      " 3.8%:    -0.01 * f1 + -0.15 * f2 + -0.11 * f3 + -0.01 * f4 +  0.68 * f5 +  0.21 * f6 +  0.25 * f7 + -0.17 * f8 +  0.20 * f9 + -0.07 * f10\n",
      " 3.2%:     0.20 * f1 +  0.20 * f2 +  0.18 * f3 +  0.23 * f4 +  0.45 * f5 + -0.21 * f6 + -0.23 * f7 + -0.16 * f8 +  0.00 * f9 +  0.16 * f10\n",
      " 2.8%:    -0.22 * f1 + -0.12 * f2 + -0.13 * f3 + -0.41 * f4 +  0.26 * f5 +  0.01 * f6 +  0.00 * f7 +  0.09 * f8 + -0.03 * f9 + -0.04 * f10\n",
      " 2.6%:    -0.03 * f1 + -0.04 * f2 + -0.03 * f3 + -0.41 * f4 +  0.16 * f5 + -0.12 * f6 + -0.16 * f7 +  0.08 * f8 + -0.07 * f9 +  0.01 * f10\n",
      " 2.3%:     0.28 * f1 +  0.05 * f2 +  0.01 * f3 +  0.31 * f4 + -0.06 * f5 +  0.08 * f6 +  0.11 * f7 + -0.06 * f8 +  0.03 * f9 +  0.02 * f10\n",
      " 2.3%:    -0.51 * f1 + -0.09 * f2 + -0.04 * f3 +  0.31 * f4 + -0.01 * f5 + -0.14 * f6 + -0.19 * f7 +  0.13 * f8 + -0.05 * f9 + -0.08 * f10\n",
      " 2.1%:    -0.25 * f1 + -0.08 * f2 + -0.05 * f3 + -0.07 * f4 +  0.19 * f5 + -0.20 * f6 + -0.14 * f7 + -0.04 * f8 + -0.04 * f9 +  0.19 * f10\n",
      " 1.8%:    -0.18 * f1 + -0.03 * f2 + -0.05 * f3 +  0.51 * f4 +  0.06 * f5 + -0.11 * f6 + -0.08 * f7 +  0.03 * f8 + -0.01 * f9 +  0.02 * f10\n",
      " 1.6%:     0.02 * f1 +  0.02 * f2 +  0.01 * f3 + -0.12 * f4 + -0.03 * f5 + -0.44 * f6 + -0.33 * f7 +  0.01 * f8 + -0.06 * f9 +  0.20 * f10\n"
     ]
    }
   ],
   "source": [
    "vars = pca_test2.explained_variance_ratio_\n",
    "c_names = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10']\n",
    "\n",
    "print('Variance:  Projected dimension')\n",
    "print('------------------------------')\n",
    "for idx, row in enumerate(pca_test2.components_):\n",
    "    output = '{0:4.1f}%:    '.format(100.0 * vars[idx])\n",
    "    output += \" + \".join(\"{0:5.2f} * {1:s}\".format(val, name) for val, name in zip(row, c_names))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_16 = pca_train2.transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11645, 27)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11645, 16)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_16 = pca_test2.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2912, 27)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2912, 16)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhongyizhang/env/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/zhongyizhang/env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5., 1., 1., ..., 3., 3., 5.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfp16 = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train_pca_16, y_train)\n",
    "y_pred_pca16 = clfp16.predict(X_test_pca_16)\n",
    "y_pred_pca16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression training set accuracy score for n = 16 PCA: 70.07 %\n",
      "Logistic regression testing set accuracy score for n = 16 PCA: 39.9 %\n"
     ]
    }
   ],
   "source": [
    "pca_16_train = round(clfp16.score(X_train_pca_16, y_train) * 100, 2)\n",
    "pca_16_test = round(clfp16.score(X_test_pca_16, y_test) * 100, 2)\n",
    "print('Logistic regression training set accuracy score for n = 16 PCA:',pca_16_train,'%')\n",
    "print('Logistic regression testing set accuracy score for n = 16 PCA:',pca_16_test,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[138,  31,  69,  64,   6],\n",
       "       [ 83,  82,  96, 214, 101],\n",
       "       [ 42,  53,  80, 240,  83],\n",
       "       [ 16,  51,  95, 312, 220],\n",
       "       [  2,  35,  34, 215, 550]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_pca16 = metrics.confusion_matrix(y_test, y_pred_pca16)\n",
    "cnf_pca16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "OVERALL_RATING 1       0.49      0.45      0.47       308\n",
      "OVERALL_RATING 2       0.33      0.14      0.20       576\n",
      "OVERALL_RATING 3       0.21      0.16      0.18       498\n",
      "OVERALL_RATING 4       0.30      0.45      0.36       694\n",
      "OVERALL_RATING 5       0.57      0.66      0.61       836\n",
      "\n",
      "        accuracy                           0.40      2912\n",
      "       macro avg       0.38      0.37      0.36      2912\n",
      "    weighted avg       0.39      0.40      0.38      2912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['OVERALL_RATING 1', 'OVERALL_RATING 2', 'OVERALL_RATING 3', 'OVERALL_RATING 4', 'OVERALL_RATING 5']\n",
    "print(\"\", classification_report(y_test, y_pred_pca16, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set after PCA when n_components = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 4., ..., 2., 5., 3.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_pca16_tr = clfp16.predict(X_train_pca_16)\n",
    "y_pred_pca16_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression training set accuracy score for n = 16 PCA: 70.07 %\n"
     ]
    }
   ],
   "source": [
    "pca_16_train = round(clfp16.score(X_train_pca_16, y_train) * 100, 2)\n",
    "print('Logistic regression training set accuracy score for n = 16 PCA:',pca_16_train,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - d. \"Training error is small and test error is big\" is an indication of overfitting. Training set accuracy score is 70.07 % and Testing set accuracy score is 39.9 %. It means that the testing RMSE is much bigger than the Training RMSE. It indicates that this logistic regression model is over-fitting for after PCA when n_compopnents = 16. The PCA model keeps 16 top features according to their importance by calculating the top variances. The model keeps so many features for modeling so that it may cause the over-fitting for the further models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1088,  302,    1,    0,    0],\n",
       "       [ 261, 1683,  325,   53,    0],\n",
       "       [   0,  745,  297,  853,    0],\n",
       "       [   0,  381,   18, 1755,  470],\n",
       "       [   0,    0,    0,   76, 3337]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_pca16_tr = metrics.confusion_matrix(y_train, y_pred_pca16_tr)\n",
    "cnf_pca16_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "OVERALL_RATING 1       0.81      0.78      0.79      1391\n",
      "OVERALL_RATING 2       0.54      0.72      0.62      2322\n",
      "OVERALL_RATING 3       0.46      0.16      0.23      1895\n",
      "OVERALL_RATING 4       0.64      0.67      0.65      2624\n",
      "OVERALL_RATING 5       0.88      0.98      0.92      3413\n",
      "\n",
      "        accuracy                           0.70     11645\n",
      "       macro avg       0.67      0.66      0.65     11645\n",
      "    weighted avg       0.68      0.70      0.67     11645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['OVERALL_RATING 1', 'OVERALL_RATING 2', 'OVERALL_RATING 3', 'OVERALL_RATING 4', 'OVERALL_RATING 5']\n",
    "print(\"\", classification_report(y_train, y_pred_pca16_tr, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 Conceptual Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) In order to better understand what is happening in Model 2 & Model 3, rerun PCA without specifying a number of components. Plot out the cumulative explained variance ratio vs number of components for the original scaled data. Describe what the plot is showing as well as what the cumulative explained variance tells us about our data.\n",
    "\n",
    "Helpful link: https://stackoverflow.com/questions/32857029/python-scikit-learn-pca-explained-variance-ratio-cutoff (Links to an external site.)\n",
    "\n",
    "b) Between Model 2 and Model 3, which performed the best? Explain why this is.\n",
    "\n",
    "c) Assuming you are working with a company on a modeling project with a massive data set, what would be some of the benefits of utilizing PCA? \n",
    "\n",
    "d) Now argue the opposite of question 3 - what is a negative result of utilizing this  dimensionality reduction technique? \n",
    "\n",
    "e) sklearn offers a variety of methods to solve a multiclass logistic regression problem. One option is the \"one-vs-the-rest\" (also known as \"one-vs-all\" method). Explain in detail what this process does.\n",
    "\n",
    "Hint: Run the .predict_proba() method for one of your prior models to have a better understanding of \"one-vs-the-rest\" output.\n",
    "\n",
    "f) Each of the three models utilized logistic regression. The Hands-On ML book describes the logistic function (sometimes called the sigmoid function) in detail. Using Equation 4-14, plot out the logistic function & describe why it is useful in classification problems of the nature covered in this homework assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from sklearn.decomposition import PCA\n",
    "# my_modelu: my_modelu is my pca model with unspecifying the value for n_components. I added a u after my_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.30203991e+00 4.12348109e+00 3.19172824e+00 2.72223065e+00\n",
      " 1.98268986e+00 1.17895782e+00 1.09587009e+00 1.01411463e+00\n",
      " 8.59917085e-01 7.50089905e-01 7.11947184e-01 6.29709081e-01\n",
      " 6.08283981e-01 5.71393787e-01 4.90859772e-01 4.29230958e-01\n",
      " 1.50948899e-01 8.87178581e-02 5.01200590e-02 3.57062253e-02\n",
      " 1.37222323e-02 6.57484234e-03 9.41002926e-04 2.27953577e-10\n",
      " 3.41913053e-11 1.69199421e-11 9.62590533e-32]\n",
      "[2.33328731e-01 1.52669076e-01 1.18171562e-01 1.00788734e-01\n",
      " 7.34077403e-02 4.36501095e-02 4.05738431e-02 3.75469029e-02\n",
      " 3.18378439e-02 2.77715674e-02 2.63593591e-02 2.33145494e-02\n",
      " 2.25212997e-02 2.11554654e-02 1.81737484e-02 1.58919836e-02\n",
      " 5.58878008e-03 3.28471821e-03 1.85566101e-03 1.32199865e-03\n",
      " 5.08056298e-04 2.43429056e-04 3.48399918e-05 8.43982580e-12\n",
      " 1.26590977e-12 6.26449320e-13 3.56392583e-33]\n",
      "[0.23332873 0.38599781 0.50416937 0.6049581  0.67836584 0.72201595\n",
      " 0.7625898  0.8001367  0.83197454 0.85974611 0.88610547 0.90942002\n",
      " 0.93194132 0.95309678 0.97127053 0.98716252 0.9927513  0.99603601\n",
      " 0.99789168 0.99921367 0.99972173 0.99996516 1.         1.\n",
      " 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "my_modelu = PCA()\n",
    "my_modelu.fit_transform(X_test_scaled)\n",
    "\n",
    "print(my_modelu.explained_variance_)\n",
    "print(my_modelu.explained_variance_ratio_)\n",
    "print(my_modelu.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.22558999e+00 4.20117284e+00 3.84347831e+00 2.69749682e+00\n",
      " 1.97460045e+00 1.65292334e+00 1.32391798e+00 1.05876656e+00\n",
      " 9.60680453e-01 8.77940805e-01 7.90320054e-01 7.70456322e-01\n",
      " 6.59364734e-01 6.20947278e-01 4.88863525e-01 4.26477746e-01\n",
      " 1.59403971e-01 9.02838004e-02 7.04925167e-02 3.60958385e-02\n",
      " 1.36183937e-02 5.34550682e-03 1.01986645e-03 2.36879813e-10\n",
      " 3.48446005e-11 1.69388965e-11 1.64400455e-31]\n",
      "[2.15051805e-01 1.45121957e-01 1.32766043e-01 9.31801742e-02\n",
      " 6.82090198e-02 5.70972626e-02 4.57323645e-02 3.65731857e-02\n",
      " 3.31849778e-02 3.03268855e-02 2.73001843e-02 2.66140274e-02\n",
      " 2.27765684e-02 2.14495065e-02 1.68869109e-02 1.47319064e-02\n",
      " 5.50632338e-03 3.11869144e-03 2.43503716e-03 1.24686580e-03\n",
      " 4.70422906e-04 1.84650915e-04 3.52294516e-05 8.18258693e-12\n",
      " 1.20364403e-12 5.85123703e-13 5.67891792e-33]\n",
      "[0.21505181 0.36017376 0.4929398  0.58611998 0.654329   0.71142626\n",
      " 0.75715863 0.79373181 0.82691679 0.85724368 0.88454386 0.91115789\n",
      " 0.93393446 0.95538396 0.97227087 0.98700278 0.9925091  0.99562779\n",
      " 0.99806283 0.9993097  0.99978012 0.99996477 1.         1.\n",
      " 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "my_modelu = PCA()\n",
    "my_modelu.fit_transform(X_train_scaled)\n",
    "\n",
    "print(my_modelu.explained_variance_)\n",
    "print(my_modelu.explained_variance_ratio_)\n",
    "print(my_modelu.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  Projected dimension\n",
      "------------------------------\n",
      "21.5%:    -0.02 * f1 + -0.14 * f2 + -0.12 * f3 +  0.16 * f4 +  0.05 * f5 +  0.28 * f6 +  0.24 * f7 +  0.26 * f8 +  0.07 * f9 +  0.30 * f10\n",
      "14.5%:    -0.06 * f1 +  0.08 * f2 +  0.09 * f3 +  0.03 * f4 +  0.04 * f5 + -0.22 * f6 + -0.17 * f7 + -0.16 * f8 +  0.22 * f9 +  0.01 * f10\n",
      "13.3%:     0.08 * f1 +  0.03 * f2 +  0.00 * f3 + -0.25 * f4 + -0.09 * f5 +  0.05 * f6 + -0.00 * f7 +  0.08 * f8 +  0.15 * f9 +  0.07 * f10\n",
      " 9.3%:     0.14 * f1 + -0.01 * f2 + -0.02 * f3 +  0.01 * f4 + -0.06 * f5 + -0.07 * f6 + -0.30 * f7 +  0.17 * f8 +  0.48 * f9 + -0.26 * f10\n",
      " 6.8%:    -0.24 * f1 +  0.60 * f2 +  0.60 * f3 + -0.03 * f4 +  0.15 * f5 +  0.13 * f6 +  0.10 * f7 +  0.14 * f8 +  0.01 * f9 + -0.02 * f10\n",
      " 5.7%:     0.29 * f1 + -0.14 * f2 + -0.13 * f3 +  0.08 * f4 +  0.07 * f5 + -0.04 * f6 + -0.02 * f7 + -0.07 * f8 + -0.01 * f9 +  0.02 * f10\n",
      " 4.6%:    -0.30 * f1 +  0.04 * f2 +  0.02 * f3 + -0.08 * f4 + -0.11 * f5 +  0.09 * f6 +  0.16 * f7 + -0.47 * f8 +  0.25 * f9 +  0.16 * f10\n",
      " 3.7%:    -0.03 * f1 + -0.14 * f2 + -0.10 * f3 +  0.24 * f4 +  0.76 * f5 +  0.10 * f6 +  0.11 * f7 + -0.03 * f8 +  0.12 * f9 + -0.13 * f10\n",
      " 3.3%:    -0.40 * f1 + -0.22 * f2 + -0.17 * f3 + -0.12 * f4 + -0.38 * f5 +  0.08 * f6 +  0.12 * f7 +  0.10 * f8 +  0.02 * f9 + -0.11 * f10\n",
      " 3.0%:     0.17 * f1 +  0.12 * f2 +  0.10 * f3 +  0.16 * f4 + -0.08 * f5 + -0.13 * f6 + -0.19 * f7 +  0.01 * f8 + -0.08 * f9 +  0.06 * f10\n",
      " 2.7%:    -0.25 * f1 +  0.02 * f2 +  0.05 * f3 +  0.59 * f4 + -0.29 * f5 + -0.06 * f6 + -0.05 * f7 +  0.01 * f8 +  0.00 * f9 + -0.02 * f10\n",
      " 2.7%:    -0.44 * f1 + -0.11 * f2 + -0.05 * f3 + -0.14 * f4 +  0.03 * f5 + -0.06 * f6 + -0.14 * f7 +  0.16 * f8 + -0.02 * f9 + -0.17 * f10\n",
      " 2.3%:    -0.26 * f1 + -0.13 * f2 + -0.10 * f3 + -0.31 * f4 +  0.20 * f5 +  0.02 * f6 +  0.01 * f7 +  0.06 * f8 + -0.00 * f9 + -0.03 * f10\n",
      " 2.1%:     0.41 * f1 +  0.09 * f2 +  0.04 * f3 +  0.08 * f4 + -0.29 * f5 +  0.25 * f6 +  0.26 * f7 +  0.01 * f8 +  0.08 * f9 + -0.18 * f10\n",
      " 1.7%:    -0.21 * f1 + -0.06 * f2 + -0.06 * f3 +  0.57 * f4 +  0.02 * f5 + -0.07 * f6 + -0.06 * f7 +  0.02 * f8 + -0.00 * f9 +  0.01 * f10\n",
      " 1.5%:     0.01 * f1 +  0.02 * f2 +  0.00 * f3 + -0.09 * f4 +  0.03 * f5 + -0.50 * f6 + -0.38 * f7 +  0.04 * f8 + -0.08 * f9 +  0.23 * f10\n",
      " 0.6%:     0.01 * f1 + -0.00 * f2 +  0.02 * f3 +  0.00 * f4 + -0.01 * f5 + -0.04 * f6 + -0.03 * f7 +  0.02 * f8 + -0.09 * f9 +  0.03 * f10\n",
      " 0.3%:     0.01 * f1 +  0.18 * f2 + -0.17 * f3 + -0.00 * f4 +  0.00 * f5 + -0.66 * f6 +  0.66 * f7 +  0.07 * f8 +  0.10 * f9 + -0.13 * f10\n",
      " 0.2%:    -0.06 * f1 +  0.66 * f2 + -0.71 * f3 +  0.01 * f4 +  0.02 * f5 +  0.17 * f6 + -0.16 * f7 + -0.01 * f8 + -0.05 * f9 +  0.03 * f10\n",
      " 0.1%:     0.01 * f1 + -0.01 * f2 +  0.00 * f3 + -0.01 * f4 +  0.01 * f5 + -0.08 * f6 +  0.17 * f7 +  0.02 * f8 + -0.21 * f9 +  0.42 * f10\n",
      " 0.0%:    -0.01 * f1 +  0.01 * f2 + -0.01 * f3 +  0.00 * f4 + -0.00 * f5 +  0.00 * f6 + -0.01 * f7 +  0.16 * f8 +  0.54 * f9 + -0.13 * f10\n",
      " 0.0%:     0.00 * f1 +  0.00 * f2 +  0.00 * f3 +  0.00 * f4 + -0.00 * f5 + -0.01 * f6 + -0.00 * f7 +  0.54 * f8 + -0.21 * f9 +  0.04 * f10\n",
      " 0.0%:    -0.00 * f1 + -0.00 * f2 +  0.00 * f3 + -0.00 * f4 + -0.00 * f5 +  0.00 * f6 + -0.01 * f7 + -0.18 * f8 + -0.02 * f9 +  0.14 * f10\n",
      " 0.0%:     0.00 * f1 + -0.00 * f2 +  0.00 * f3 + -0.00 * f4 + -0.00 * f5 +  0.00 * f6 + -0.00 * f7 +  0.00 * f8 +  0.00 * f9 +  0.00 * f10\n",
      " 0.0%:    -0.00 * f1 +  0.00 * f2 + -0.00 * f3 +  0.00 * f4 + -0.00 * f5 +  0.00 * f6 + -0.00 * f7 +  0.08 * f8 +  0.44 * f9 +  0.65 * f10\n",
      " 0.0%:     0.00 * f1 +  0.00 * f2 + -0.00 * f3 + -0.00 * f4 + -0.00 * f5 + -0.00 * f6 +  0.00 * f7 + -0.47 * f8 + -0.06 * f9 + -0.10 * f10\n",
      " 0.0%:    -0.00 * f1 + -0.00 * f2 +  0.00 * f3 + -0.00 * f4 + -0.00 * f5 + -0.00 * f6 +  0.00 * f7 + -0.00 * f8 + -0.00 * f9 + -0.00 * f10\n"
     ]
    }
   ],
   "source": [
    "# Giving an example here:\n",
    "vars = my_modelu.explained_variance_ratio_\n",
    "c_names = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10']\n",
    "\n",
    "print('Variance:  Projected dimension')\n",
    "print('------------------------------')\n",
    "for idx, row in enumerate(my_modelu.components_):\n",
    "    output = '{0:4.1f}%:    '.format(100.0 * vars[idx])\n",
    "    output += \" + \".join(\"{0:5.2f} * {1:s}\".format(val, name) for val, name in zip(row, c_names))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I do not specify the n_components value, the PCA model will show all the variances of every feature. This will not filter the most important features. However, by visualizing the data set, it is always good for data scientists to list the variances rank of each feature by descending order so that data scientists will be able to decide to choose how many features for further modeling regarding their importance. Unspecifying n_components will show all the feature importance by calculating the variances of each feature, but it is still a good visualization process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)     \n",
    "model 2 - PCA with n_components = 2    \n",
    "model 3 - PCA with n_components = 16    \n",
    "I would say model 3 performs better. Although model 3 has very high testing RMSE with very low training RMSE and is over-fitting, the testing accuracy score is still higher than the accuracy score of model 2. The main use of PCA is to reduce the size of the feature space while retaining as much of the information as possible. Model 2 only keeps 2 top features, which are definitely not good enough for accurate modeling. There are abundant mistaken classification predictions in the confusion matrix of model 2. Model 3 obviously took so many features including some not very necessary features. This is the reason why model 3 is seriously over-fitting. I would prefer to pick some values for n_components between 2 and 16. In conclusion, compared with model 2 and model 3, I still prefer model 2 as a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) The advantage of PCA (one method of dimension reduction) in the context of ML (ie. neural networks) would be to reduce the risk of over fitting and reduce computational complexity. The very high dimensional nature of many data sets makes direct visualization impossible as we humans can only comprehend three dimensions. The solution is to work with data dimension reduction techniques. When reducing the dimensions of data, its important not to lose more information than is necessary. The variation in a data set can be seen as representing the information that we would like to keep. Principal Component Analysis (PCA) is a well-established mathematical technique for reducing the dimensionality of data, while keeping as much variation as possible.\n",
    "\n",
    "One of the keys behind the success of PCA is that in addition to the low-dimensional sample representation, it provides a synchronized low-dimensional representation of the variables. The synchronized sample and variable representations provide a way to visually find variables that are characteristic of a group of samples.The figure below shows one example of how it might look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) \n",
    "1. PCA assumes that the principle components are a linear combination of the original features. If this is not true, PCA will not give you sensible results.    \n",
    "2. PCA uses variance as the measure of how important a particular dimension is. So, high variance axes are treated as principle components, while low variance axes are treated as noise.     \n",
    "3. PCA assumes that the principle components are orthogonal.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) The one-vs-the-rest meta-classifier also implements a `predict_proba` method, so long as such a method is implemented by the base classifier. This method returns probabilities of class membership in both the single label and multilabel case.  Note that in the multilabel case, probabilities are the marginal probability that a given sample falls in the given class. As such, in the multilabel case the sum of these probabilities over all possible labels for a given sample *will not* sum to unity, as they do in the single label case.\n",
    "\n",
    "This strategy, also known as one-vs-all, is implemented in OneVsRestClassifier. The strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only n_classes classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy and is a fair default choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Equation 4-14 in the text book \"Hands on ML\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Equation 4-14 in the text book \"Hands on ML\":\n",
    "# (t)= 1/(1+e**(t))\n",
    "  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import math\n",
    "\n",
    "def graph(formula, x_range):  \n",
    "    x = np.array(x_range)  \n",
    "    y = formula(x)  # <- note now we're calling the function 'formula' with x\n",
    "    plt.plot(x, y)  \n",
    "    plt.show()  \n",
    "e=math.exp(1)\n",
    "def my_formula(x):\n",
    "    return (1+e**(-x))**(-1)\n",
    "\n",
    "graph(my_formula, range(-10, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAADQCAYAAAAzmqprAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3wU1f3/8dch3ASigoByFS8oRCxXkVqRaaUKWAFBLvpAEW0pFttixQr1J1j5ilj5qlilrVpFRQtqsaICClYQRfyGS1REFkKAEIRAAgTCJYTk/P44myWEhCyym9lN3s/HYx47Z+bs7meYmeWTM2fOGGstIiIiIrGgmt8BiIiIiBRRYiIiIiIxQ4mJiIiIxAwlJiIiIhIzlJiIiIhIzFBiIiIiIjGjul9f3LBhQ9uqVSu/vl5EKkAgEADg0ksv9TkSEYm2lStXZllrG53u5/iWmLRq1YoVK1b49fUiUgE8zwNg8eLFvsYhItFnjNkSic/RpRwRERGJGUpMREREJGYoMREREZGYocREREREYoYSExEREYkZSkxEREQkZigxERERkZihxERERERiRrkDrBljXgJ+Aey01rYrZb0BpgF9gIPAHdbaVZEMMi8vj927d7N//34KCgoi+dEiFSohIYHExEQaNGhArVq1/A5HRCTmhDPy6wzgWeDVMtb3BloHpyuBvwVfIyIvL4/09HTq169Pq1atqFGjBi4XEokv1lry8/PZt28f6enptGzZUsmJiEgJ5V7KsdZ+Cuw+SZV+wKvWWQ6cbYxpUt7nBgIBZsyYAUB+fj6e5zFz5kwADh48iOd5zJ49m927d3PmmWeSnZ3NgQMHMMaQn59PIBBg7969ofcHAgFycnIAOHLkCIFAgH379gEuuQkEAuzfvx+Aw4cPEwgEyM3NBeDQoUMEAgEOHDgQ+v5AIMDBgwcBOHDgAIFAgEOHDgGQm5tLIBDg8OHDAOzfv59AIEBeXh4A+/btIxAIcOTIEQBycnIIBALk5+cDsHfv3uPKe/bsIRAIcPToUQB2795NIBAItQ5lZ2cTCAQoLCwEICsrK/QMEoBdu3YdV965cyfr168PlTMzM9mwYUOovGPHDlJTU0Pl7du3s3HjxlD5+++/Jy0tLVTetm0bmzZtCpUzMjLYvHlzqLx161a2bDk2EnF6ejrp6emh8pYtW9i6dWuovHnzZjIyMkLlTZs2sW3btlA5LS2N77//PlTeuHEj27dvD5VTU1PZsWNHqLxhwwYyMzND5fXr17Nz585QORAIsGvXruPKWVlZABQWFhIIBMjOzgagoKCAQCDA7t3ukD969CiBQIA9e/YAnNaxZ4yhsLCQ7OxszjjjDHbv3s2aNWvwPI/k5GQAUlJS8DyPlJQUAJKTk/E8jzVr1gCwbNkyPM8L7e8lS5bgeV5ofy1atAjP80L/3gsWLMDzvNC/13vvvYfneaHtnzNnDp7nheKfPXs2nueFjv2ZM2fieV7oWJ0xY0ZomHmAF154gZ49e4bK06dPp3fv3qFyRkZGKHaAqVOnMnDgwFB5ypQpDB06NFSeNGkSw4YNC5UnTJjAiBEjQuXx48czcuTIUHns2LGMHj06VB4zZgxjxowJlUePHs3YsWND5ZEjRzJ+/PhQecSIEUyYMCFUHjZsGJMmTQqVhw4dypQpU0LlgQMHMnXq1FC5b9++TJs2LVTu3bs306dPD5V79uzJCy+8ECp7nhfW7x643w3P85gzZw7gznvP83jvvfcAdx57nseCBQsAdx56nseiRYsAdx55nseSJUsAd9x7nseyZcsAfDv2du3K4sgReP31ufzkJ30JBPaxZQs8/fQHXHHFHXzxxSGSk2HixAV06PA7PvzwKB9+CPfeu4h27f7EnDnw5pvwy1/+l8sum8KMGfDii3DLLYu57LJnefZZmDYN+vf/lKSkl3n8cXjsMejdeylJSf/iz3+GiRPhZz/7nKSkdxg/Hh54AK6+ehlJSR9w333whz/AlVd+QVLSQn73O7jnHujc+QuSkhZz990wahS0b/8Fl132Gb/6Ffzyl3DZZcu57LIvufNOGDEC2rRZTrt2yQwfDrffDq1bf0G7dqu57TYYNgwuuugLLr/8K269FW69FVq1WsaPfrSGW26BoUOhZctltG+/liFDYMgQaN58Ge3bBxg8GAYPhqZNP6NDhw0MGgSDBsF55y2lU6dUbr4Zbr4ZGjf+lM6d07j5Zhg4EBo1WkKXLpsZOBBuuqmQRo0+5Yor0hkwAPr1O0qjRp/StWsGAwbAjTfm06jRp3Trto0BA+CGG/Jo2HApP/7xdm66CXr3PkzDhku56qpMbroJevU6SMOGS4mUSDwrpxmwtVg5I7hse8mKxpiRwEgg7L8U9+/fT4sWLUL/EYhUBvXq1TsueRKJNXl5hiNHGpCWVpPcXPjyy7PZtasH//73mdSrB19/3ZK0tF/x8MPnUKMGpKW145tvJjN0aCOshczMq9i+/VWuuKIR+fmQm9uLQ4euo3Hjot/+vkBf2rQp+sYbgBu46qqici+gF716FZV7Aj05ltf+DPgZx/JWD/D47W+LytcA1zBuXFG5OwAPP1xU/gkA331XVL6qRPnHYZXXri0qdyu1/O23x9cvWT6Wt7vv/+abY+WtW+Hrr4+Vt20rXr6a7dvhq6+ObV9mJqxeXVS+hl27YFWoY0UPsrJg5UpwbRLXkJUF7pF11UNll6fWCJWdWkB3gn+/AbWB7nzxRVG5DkX/vpFgrLXlVzKmFfB+GX1M3gemWGs/C5Y/Bh6w1p70CX1dunSx4TzE77vvvqNNmza6fCOVirWWdevW0bZtW79DiSo9xC92HDwI338PmZmwY8ex1507ITsbsrKOve7eDcEG4KioXh1q1XJTzZpQo8aJr9Wrn/haNCUkHHstOZ+QANWqnVguPhlz/HJj3FQ0X9qyU5ng5PNlLSu5/mTLSq6L1LKyhFN3wACz0lrbJfxPLV0kWky2AS2KlZsHl0WMkhKpbHRMS6Tt3QsbN0JamnvdsgW2boWMDPe6+2QX5EtRowbUrw9nn+2mM890U2LisalePTfVqQN167qpTh044ww31a597LV27WPJSEJCdP4NpHKIRGIyF7jHGDML1+k1x1p7wmUcERE5PYWFkJ7uLhcUnzZsKD/xqFkTmjaF885z07nnutfGjeGcc6Bhw2OvDRq4hEL5s/ghnNuF/4W7eNfQGJMBTMRdgMJa+3dgHu5W4VTc7cIjSv8kEREJV0EBBAKuT8DKla6vwOrVEOyzf4I6deCii+DCC91rq1bQooWbmjeHRo3cZQmRWFduYmKtvaWc9RYYfbI6IiJycocOwZdfwtKlbvrii9KTkHPPhcsug6SkY9Oll7rlauGQyiASl3JEROQUFRa6VpD582HBAnc3RPCu7JCWLaFz52NTp07u0otIZabERCq9Tz/9lKlTp7Jy5Uq+//57Xn75Ze644w6/w5IqaP9+mDfPTQsWuDtiihgDHTpA9+5uuvpqaFLuiFAilY8SE6n0cnNzadeuHbfffju333673+FIFXPwIHzwAcye7V6D4zICrkWkd2839ejh7n4RqeqUmEil16dPH/r06QOglhKpEIWF8Mkn8NJL8O67EBxUGnAtIf37u2SkbVv1CxEpSX20q4Dhw4fTuHHj0JD74Vi5ciXGGF588cUoRiZSuWRlwdSp0KYN9OwJb7zhkpKuXeHJJ914IkuXwn33uU6rSkpETqTEpJJLTk7mtddeY9y4cdStW/eE9U899RTGGN54443jlnfu3Jn+/fvz0EMPhZ4pJCKlW7XKPf+kWTO4/343rkjz5m74840b3d02997rlonIySkxqeQefPBBzjzzTO6+++5S1690D06gc+fOJ6wbP348O3bs4JlnnolqjCLxaulSd0mmc2d4/XV3V02fPu7yzaZN7mFxF17od5Qi8UWJSSW2fv16Fi1axODBgznjjDNKrbNy5Urq1avHJZdccsK6rl270qZNG/7xj3+EnmwsUtVZ627x7d4drrnG3V1Tt657Im1amuvg2reve36LiJw6JSZxJjc3l0ceeYSOHTuSmJiIMabUKTMzk5deeglrLUOGDDnhc8aNG4cxhnXr1pGbm0u1atVC733ttddC9YYOHUp6ejoLFy6syM0UiUn/938uIenTBz77zN1FM2GCey7N//6vG21VRE6Pcvo4snPnTnr06MG6dev40Y9+xKhRo8jLy+Ott95ix44d1KhRg5YtW9KwYUPOPfdcFi1aREJCAt26dTvhszp16sTw4cN55ZVXuOqqq/j5z38eWlf0RFiAn/zEPRp84cKFXH/99VHfxmjIzc0lNTUVgMLCQtLT00lJSaFBgwa0bNnS5+gkHmzZAn/6k+vMCm549/vvh1Gj3MPsRCRylJjEkVtvvZV169bxxz/+kSlTpoSeUHv//ffTunVrCgoKWL58OQ0bNuTAgQOkpKTQtm3bUju9Dh48mL179/LKK68wfPhwRo4cWep3XnHFFYAbpKw8Tz/9NHv37g17ezp06ED//v3Drv9DrVixgp/+9Keh8sSJE5k4cSLDhw9nxowZUf9+iV/798Njj7k7avLy3JNx770Xxo93T9oVkciL68QkXm61s/b0P2PhwoV8/PHHXH311Tz22GOhpASgRYsWdO/enUWLFpGSkkLPnj3Ztm0bBQUFNDnJ0JGrVq0CXOtJWc466yxq165Nenp6uTE+/fTTbNmyJextGj58eIUkJp7nYSOxE6RKmT8ffv1rd4svwC23uCTl/PP9jUuksovrxKQqmTlzJgBjxoyhWimPCD3rrLMAQp1Us7OzAahfv36Zn7lq1Spq1KjB5ZdfftLvbtCgAZmZmeXGuHnz5nLriMS67GzXKlLU1apLF3j2WbjySn/jEqkq4joxqUp/BC9dupRq1arRq1evUtdnZGQAcPHFFwOE7sI5XHz862KOHj3KN998Q1JSErVq1Trpdx86dKjMu3pEKgtr4e234Z573DNsateGSZNgzBjdYSNSkXS6xYGCggK2bNlC48aNS+0vkpmZSXJyMhdccAEXBgdNaBx8BGlRy0lJa9eu5fDhwye9jAOuBWbv3r1ccMEF5cYZqT4mJl6u0ZVDl4/ix759MHKke54NuNuAX3wRWrf2Ny6RqkiJSRwounSzf/9+CgsLT7iU85e//IXCwkJ+/etfh5Y1adKERo0aEQgESv3MlJQUADp27HjS7w4EAlhr6dChQ7lxRqqPif5Dl4q0ejUMGuRGaK1XD554wiUppVwxFZEKoFMvDhhjaN++PQcOHOBf//rXcevefvttnn76adq0acPvf//7495zzTXXkJWVFbpVtriilpQzy7m1YPny5QDH3dVSls2bN2OtDXuqTHfEpKWlMXfuXL/DkFNgLUyfDt26uaSkfXtYudLdAqykRMQ/ajGJExMmTGDAgAGMGDGCBQsW0KJFC5KTk1m0aBGtW7dm3rx51K5d+7j3DBw4kH//+998+OGHob4nRYqGoH/wwQdZs2YNdevW5bLLLmPQoEHH1fvoo49ISEigX79+0d3AODd//nz2799P3759/Q5FwpCTA7/6Fbz1liuPGgVPPeX6lYiIz8L5yxboBQSAVGBcKetbAp8Aq4GvgT7lfWbnzp1tONauXRtWvargP//5j/3xj39s69SpY8844wzbvn17++ijj9r9+/eXWj8vL882btzYdu3atdT1f/3rX+0ll1xia9WqZQH7pz/96bj1e/futbVr17b9+vWL+LZUJosXL7b169e3F198se3QoYPNzc0N631V4dju0aOH7dGjh99hHCc11dpLL7UWrE1MtHbWLL8jEqkcgBX2FFrNy5rCSUoSgI3AhUBN4CsgqUSd54G7g/NJwObyPleJScWYPHmyBeyqVatO+b3PPPOMBezSpUujENnJLVmyxN544422adOmFrAvv/xyhcdwKnr06GE3bdp0Su+pCsd2rCUmS5dae8457pfv8sut3bDB74hEKo9IJSbhXEntCqRaa9OstUeAWUDJdn0LFHVWOAv4/lRabSR67r33Xlq2bMmECRNO6X2HDh3iscceY+DAgVx99dVRiq5subm5tGvXjmnTpv2gW5XvuOMOHn744YjF06FDB9q1a3fC9P337lBPT0+nlR6UEtNefx2uvdaNU9K7t3vWTYkrnCISA8LpY9IM2FqsnAGUHGroYeAjY8xvgbpAz9I+yBgzEhgJ6BklFaR27dq89tprfPLJJxw4cKDU241Ls3nzZkaOHMkdd9wR3QDL0KdPH/r06QMQ9Ri2bdvG+PHj+eCDDygoKODaa69l+vTpnHvuuaE6RXcxlSYjI4OmTZtGNUb54ayFP//ZTQC//a0bYl5jk4jEpkj1Pb8FmGGtbQ70AV4zxpzw2dba5621Xay1XRo1ahShr5byXHPNNUycODHspASgbdu2PPzww5W+FWDTpk106tSJZs2a8dlnn7F48WKysrIYNWpU2J+xZcuWkw79L/45ehSGD3dJSbVq8MwzblJSIhK7wjk9twEtipWbB5cVdxeugyzW2i+MMbWBhsDOSAQpEi2jRo3irrvuYvLkyaFlDz30EAMGDAj7M9q1a0daWhqXX345s2fPJikpKRqhyinKy3PPt3nnHTc+yezZEGyEE5EYFk5ikgy0NsZcgEtIhgK3lqiTDlwLzDDGtAVqA7siGajIyUyePPm45CIvLw9jDFOnTg0tmz9/Pt27dw+Vt2zZwkcffcTSpUt55plnQssLCgqoU6dO2N991llnsXLlytPcAomkQ4dgwABYsADOPtu96lk3IvGh3MTEWnvUGHMP8CHuDp2XrLXfGmMewfXAnQvcB7xgjLkX1xH2jmAPXZEKMWrUKAYPHhwqP/DAAzRr1ozf/e53oWXNmjU77j1fffUVZ555ZqlJRc2aNaMXrETV/v3Qty8sXgwNG8LChRDGwMUiEiPCutJqrZ0HzCuxbEKx+bXATyIbmkj4GjRoQIMGDULlxMREGjRocMLAcsXVqFGDAwcOcN5551GvXr2KCFOibO9ed8fN8uXQpAl8/DG0bet3VCJyKjTwssSk3NxcUlJSSElJobCwkPT0dFJSUkhPT4/Yd3Tr1o369etz2223sXr1ajZu3MjChQsZPXo0hYWFEfseqRg5Oe524OXL4fzzYelSJSUi8UiJicSkFStW0LFjRzp27MihQ4eYOHEiHTt2POXxWE6mfv36zJ8/n5ycHH7605/SoUMHxo4dS/PmzU94UKLEtgMH4IYbYNUquOgil5RcdJHfUYnID6Gb5iQmeZ53Wk8ZDvcBgV26dOG///3vD/4e8V9eHtx0E3z+ObRo4S7ftGhR/vtEJDbpz0IRiVtHj7pbghcuhMaNYdEidxlHROKXEhMRiUuFhXDnnW6ckrPPdsnJJZf4HZWInC4lJiISd6yF3/0OXnsN6tZ145T86Ed+RyUikaDERETizhNPwHPPQa1a8N57GjxNpDJRYiIiceXNN+GBB8AY98Tgn/7U74hEJJLiIjHRILJS2eiY/mE+/xxuv93NP/EEDBzobzwiEnkxn5gkJCSQn5/vdxgiEZWfn09CQoLfYcSVDRugXz93e/BvfgN/+IPfEYlINMR8YpKYmMi+ffv8DkMkovbt20diYqLfYcSNrCz3ZODsbDeQ2rRp7lKOiFQ+MZ+YNGjQgD179pCVlcWRI0fUBC5xy1rLkSNHyMrKYs+ePcc920fKlpcH/ftDaip07AizZkF1DQ0pUmnF/Oldq1YtWrZsye7du9m8eTMFBQV+hyTygyUkJJCYmEjLli2pVauW3+HEPGth9GjXt6R5c3j/fdDzFkUqt5hPTMAlJ02aNKFJkyZ+hyIiFei55+Cf/4QzzoB334WmTf2OSESiLeYv5YhI1bR4MYwZ4+b/+U/o1MnXcESkgigxEZGYs3kzDBoEBQXwxz+65+GISNWgxEREYsqBA66za1YW9OoFkyf7HZGIVCQlJiISM6yFu+6Cr76Ciy+GN94ADfciUrWElZgYY3oZYwLGmFRjzLgy6gw2xqw1xnxrjHkjsmGKSFXw1FMwe7a78+bdd6F+fb8jEpGKVu5dOcaYBOA54OdABpBsjJlrrV1brE5rYDzwE2vtHmNM42gFLCKV02efuf4kAK+8AklJ/sYjIv4Ip8WkK5BqrU2z1h4BZgH9StT5FfCctXYPgLV2Z2TDFJHKLDMTBg92nV3vuw8GDPA7IhHxSziJSTNga7FyRnBZcZcAlxhjPjfGLDfG9IpUgCJSuR096u662b4drr4aHnvM74hExE+RGmCtOtAa8IDmwKfGmMuttXuLVzLGjARGArRs2TJCXy0i8WzCBPjkEzj3XNe/pEYNvyMSET+F02KyDWhRrNw8uKy4DGCutTbfWrsJWI9LVI5jrX3eWtvFWtulUaNGPzRmEakk3nvPtZBUq+aegaORXUUknMQkGWhtjLnAGFMTGArMLVHnP7jWEowxDXGXdtIiGKeIVDKbNsHtt7v5yZPB83wNR0RiRLmJibX2KHAP8CHwHfCmtfZbY8wjxpi+wWofAtnGmLXAJ8D91trsaAUtIvHtyBEYMgT27oUbb4T77/c7IhGJFWH1MbHWzgPmlVg2odi8Bf4QnERETmrcOEhOhpYtYcYMdylHRAQ08quIVLB333UDqVWv7jq7Nmjgd0QiEkuUmIhIhdmyBe64w81PmQLduvkajojEICUmIlIh8vNh6FDXr+QXv4A/6MKviJRCiYmIVIg//QmWL4cWLVy/EmP8jkhEYpESExGJug8+gKlT3ZOCZ82Cc87xOyIRiVVKTEQkqvLyGjF8uJt/9FG46ip/4xGR2BapIelFRE5gbQLffff/yMmB66/XeCUiUj7fWkwCgQAzZswAID8/H8/zmDlzJgAHDx7E8zxmz54NQE5ODp7nMWfOHACysrLwPI/33nsPgB07duB5HgsWLABg69ateJ7HokWLAEhLS8PzPJYsWRL6bs/zWLZsGQBr1qzB8zySk5MBSElJwfM8UlJSAEhOTsbzPNasWQPAsmXL8DyPQCAAwJIlS/A8j7Q0N9jtokWL8DyPrVvdsw8XLFiA53ns2LEDgPfeew/P88jKygJgzpw5eJ5HTk4OALNnz8bzPA4ePAjAzJkz8TyP/Px8AGbMmIFXbJjMF154gZ49e4bK06dPp3fv3qHytGnT6Nu3b6g8depUBg4cGCpPmTKFoUOHhsqTJk1i2LBhofKECRMYMWJEqDx+/HhGjhwZKo8dO5bRo0eHymPGjGHMmDGh8ujRoxk7dmyoPHLkSMaPHx8qjxgxggkTQsPiMGzYMCZNmhQqDx06lClTpoTKAwcOZOrUqaFy3759mTZtWqjcu3dvpk+fHir37NmTF154IVT2PE/HXgUde99805+cnPY0aQKvvgpPPqljT8eefvegch57kaJLOSISFR9/DHv2jAYKef11aNzY74hEJB4YN2hrxevSpYtdsWKFL98tItGVmQkdOsCOHXD++TPYvPkOv0MSkSgzxqy01nY53c9Ri4mIRFRhoXs4344dcNZZKZx//qt+hyQicUSdX0Ukoh5/HD76CBo2hIsv/h+MKfQ7JBGJI2oxEZGI+ewzeOghN//KK1CrVpa/AYlI3FFiIiIRkZXlhpwvKIA//hH69PE7IhGJR0pMROS0FfUr2bbNDaD2P//jd0QiEq+UmIjIaZs6FebPhwYN3JDzNWr4HZGIxCslJiJyWpYtcw/oA9evpEULf+MRkfimxEREfrDsbBgyxPUrGTsWfvELvyMSkXgXVmJijOlljAkYY1KNMeNOUm+gMcYaY057gBURiW2FhXDbbZCRAd26weTJfkckIpVBuYmJMSYBeA7oDSQBtxhjkkqplwj8Hvgy0kGKSOx59FH1KxGRyAunxaQrkGqtTbPWHgFmAf1KqTcJeBw4HMH4RCQGLVwIEyeCMfDGG3D++X5HJCKVRTiJSTNga7FyRnBZiDGmE9DCWvtBBGMTkRi0dSvceitYCxMmwPXX+x2RiFQmp9351RhTDXgSuC+MuiONMSuMMSt27dp1ul8tIhXsyBEYPNgNpnbddcdGeRURiZRwEpNtQPEbAJsHlxVJBNoBi40xm4FuwNzSOsBaa5+31nax1nZp1KjRD49aRHwxdiwsX+5uCX79dUhI8DsiEalswklMkoHWxpgLjDE1gaHA3KKV1toca21Da20ra20rYDnQ11q7IioRi4gvZs2Cv/7VdXJ96y33kD4RkUgrNzGx1h4F7gE+BL4D3rTWfmuMecQY0zfaAYqI/1avhjvvdPNPPQVXXulvPCJSeVUPp5K1dh4wr8SyCWXU9U4/LBGJFTt3Qv/+cOgQjBgBv/mN3xGJSGWmkV9FpEz5+TBoEKSnu1aSv/3N3SIsIhItSkxEpEz33guffgpNmsCcOVCrlt8RiUhlp8REREr14ovw3HNQsya88w40bep3RCJSFSgxEZETfP75sb4kf/+7OruKSMVRYiIix0lNdZ1d8/Pht791HV5FRCqKEhMRCcnOhj593MiuvXrBk0/6HZGIVDVKTEQEgMOHXUvJhg3Qvj28+SZUD2tAARGRyFFiIiIUFrpLNp99Bs2awQcfQGKi31GJSFWkxEREeOghN+R8vXouKWnWrPz3iIhEgxITkSru+edh8mT3QL633nKXcURE/KLERKQKmzULRo1y89Onuw6vIiJ+UmIiUkW9/z7cdhtYC48+CiNH+h2RiIgSE5Eq6ZNP4Oab4ehReOABGD/e74hERBwlJiJVzPLlcOONkJcHd98Njz2mB/OJSOxQYiJShXz9NfTuDQcOwLBh8OyzSkpEJLYoMRGpIlauhJ/9DPbudQOpvfwyVNMvgIjEGP0siVQBn3/ukpLsbLjhBnc3jkZ1FZFYpMREpJL7+GO47jrYtw8GDYI5c6BWLb+jEhEpnRITkUrsgw9cC8nBg3D77fDGG1Czpt9RiYiULazExBjTyxgTMMakGmPGlbL+D8aYtcaYr40xHxtjzo98qCJyKt580/Ulyctzg6i9/LIu34hI7Cs3MTHGJADPAb2BJOAWY0xSiWqrgS7W2h8BbwN/iXSgIhIea+Hxx2HIEDdOyX33uVFd1fiPfvoAAA3pSURBVNFVROJBOD9VXYFUa22atfYIMAvoV7yCtfYTa+3BYHE50DyyYYpIOI4cgV/+EsYF2zWnTIEnntAtwSISP8Jp2G0GbC1WzgCuPEn9u4D5pa0wxowERgK0bNkyzBBFJBx79sDAgW5U1zPOgJkzYcAAv6MSETk1Eb3ibIwZBnQBepS23lr7PPA8QJcuXWwkv1ukKktNdZ1c16+H886DuXPhiiv8jkpE5NSFcylnG9CiWLl5cNlxjDE9gQeBvtbavMiEJyLl+c9/XBKyfj1cfjl8+aWSEhGJX+EkJslAa2PMBcaYmsBQYG7xCsaYjsA/cEnJzsiHKSIlHTkCY8bATTe50Vz79XMDqekqqYjEs3Iv5Vhrjxpj7gE+BBKAl6y13xpjHgFWWGvnAk8A9YC3jOtll26t7RvFuEWqtE2b3F03ycnuFuC//MUlKerkKiLxLqw+JtbaecC8EssmFJvvGeG4RKQMb7/t7rzJyYHzz4fZs+HKk3VHFxGJIxrZQCROZGbC4MFuWPmcHHfpZvVqJSUiUrkoMRGJcdbCa69BUhK89RbUrQvPPgvvvAP16/sdnYhIZGmAapEYlp7uhpOfHxwZ6Lrr4B//gFatfA1LRCRq1GIiEoMOHICHH4a2bV1SUr8+zJgBCxYoKRGRyk0tJiIxpKAAXn0VHnwQtm93ywYNgmeecQOniYhUdkpMRGKAtfDxxzB2LHz1lVvWpQs8+SR07+5vbCIiFUmXckR8ZC28/z5cdRX8/OcuKWnRwj3n5ssvlZSISNWjFhMRHxQUuPFIJk+Gr792yxo0cC0mY8a4h/CJiFRFSkxEKlBWluvE+ve/w8aNblnTpi4h+dWvoF49X8MTEfGdEhORKLMWPvvMJSNvv+2ecQNw4YXwwAMwfDjUquVvjCIisUKJiUiUrF/vhov/17/gu+/cMmPghhvg17+G3r3dc25EROQY/SyKRNCmTfDmmy4hWb362PLzzoO77nKXa84/37/4RERinRITkdOQlwdLl7pB0ObPP9YyAnDmmdC/PwwdCj17Qo0a/sUpIhIvlJiInIL8fNcSsnQpLFkC//2vG6W1SGIi/OIXMGQIXH891K7tX6wiIvFIiYnISezYAStXwooVLhn54gs4ePD4Opdf7vqL9O7txiOpWdOfWEVEKgMlJiK4O2VSU2HtWlizxiUjq1bB99+fWLd1azfwWffu7hJN8+YVH6+ISGWlxESqjIIC2LoV0tLcGCIbNx5LRjZsgKNHT3xPYiJ06uSmq66Cq6/WM2tERKJJiYlUCrm5kJnpLr1kZrqWjowMl4gUTdu2uT4ipTHGjSuSlOSmjh2hc2e46CKopgc3iIhUmLASE2NML2AakAC8aK2dUmJ9LeBVoDOQDQyx1m6ObKhSmVnr+m7s339s2rcP9u49ftq9G7Kz3ZSV5V537Tq+A+rJNGniEpCLLjo2tW0LbdpAnTrR3UYRESlfuYmJMSYBeA74OZABJBtj5lpr1xardhewx1p7sTFmKPA4MCQaAUt4rIXCwmNTQcGJrwUF7vJFyfmjR4+f8vOPTUXlI0eOvRZNeXlw+LB7LZoOH4ZDh46fDh5004EDbjp40LV4FBb+8O2tXdtdYjn3XPd63nnuYXjNmx97bd5cyYeISKwLp8WkK5BqrU0DMMbMAvoBxROTfsDDwfm3gWeNMcZaa8v60NWrD5OYGPhBQYMJa5m1pdU79c8r/XPMca/H1ylvnSlnmcHaaqWsK2u+WmiZe59bFm+qVcsjIeFgcDpE9eoHqF59P9Wr5x431aiRQ/Xq+6hRI4caNdxrQsIBTPCfr6h1Zd06f7dHICUlBQDP8/wNRETiRjiJSTNga7FyBnBlWXWstUeNMTnAOUBW8UrGmJHASFfqTG7upT8oaAlXIWAxphBjCoHCEvMFobIxBcWWlTYdpVq1o6F5V84v9lpAtWpHqFbtCMbkU61a0ZQXXJ4Xmk9IyCMh4TDVqh0iIeFwaHIxiIhIVVahnV+ttc8DzwMkJXWxr756Yh0TZiNHafWiuaxo/mTLir+Wt6ysctFUrVrZy4qvS0g4tqxoedEyY4paTRJO3DiRClDUUrJ48WJf4xCR6DPh/gdejnASk21Ai2Ll5sFlpdXJMMZUB87CdYItU5060KXLKUQqIiIilV44HRGSgdbGmAuMMTWBocDcEnXmAsOD8zcD/z1Z/xIRERGR0pTbYhLsM3IP8CHumsBL1tpvjTGPACustXOBfwKvGWNSgd245EVERETklITVx8RaOw+YV2LZhGLzh4FBkQ1NREREqpr4u6dUREREKi0lJiIiIhIzlJiIiIhIzFBiIiIiIjFDiYmIiIjEDCUmIiIiEjOUmIiIiEjMUGIiIiIiMcP4NXK8MWY/EPDly/3XkBJPXq5Cquq2V9XtBm27tr3qqarbfqm1NvF0P6RCny5cQsBaWyUf42eMWaFtr1qq6naDtl3bXvVU1W03xqyIxOfoUo6IiIjEDCUmIiIiEjP8TEye9/G7/aZtr3qq6naDtr2q0rZXPRHZbt86v4qIiIiUpEs5IiIiEjOimpgYYwYZY741xhQaY7qUWDfeGJNqjAkYY64v4/0XGGO+DNabbYypGc14oyUYe0pw2myMSSmj3mZjzDfBehHp3ew3Y8zDxphtxba/Txn1egWPhVRjzLiKjjPSjDFPGGPWGWO+Nsa8Y4w5u4x6lWafl7cPjTG1gudCavC8blXxUUaeMaaFMeYTY8za4O/d70up4xljcoqdBxP8iDUayjuGjfNMcL9/bYzp5EeckWSMubTYvkwxxuwzxowpUafS7HNjzEvGmJ3GmDXFljUwxiw0xmwIvtYv473Dg3U2GGOGh/WF1tqoTUBb4FJgMdCl2PIk4CugFnABsBFIKOX9bwJDg/N/B+6OZrwVMQH/C0woY91moKHfMUZ4ex8GxpZTJyF4DFwI1AweG0l+x36a230dUD04/zjweGXe5+HsQ+A3wN+D80OB2X7HHaFtbwJ0Cs4nAutL2XYPeN/vWKO0/Sc9hoE+wHzAAN2AL/2OOcLbnwDsAM6vrPscuAboBKwptuwvwLjg/LjSfuOABkBa8LV+cL5+ed8X1RYTa+131trSBlHrB8yy1uZZazcBqUDX4hWMMQb4GfB2cNErQP9oxhttwW0aDPzL71hiTFcg1VqbZq09AszCHSNxy1r7kbX2aLC4HGjuZzwVIJx92A93HoM7r68NnhNxzVq73Vq7Kji/H/gOaOZvVDGlH/CqdZYDZxtjmvgdVARdC2y01m7xO5BosdZ+Cuwusbj4+VzW/8/XAwuttbuttXuAhUCv8r7Prz4mzYCtxcoZnHginwPsLfbjXlqdeNMdyLTWbihjvQU+MsasNMaMrMC4ou2eYBPuS2U094VzPMSzO3F/MZamsuzzcPZhqE7wvM7BneeVRvDyVEfgy1JW/9gY85UxZr4x5rIKDSy6yjuGK/v5PZSy/9isrPsc4Fxr7fbg/A7g3FLq/KB9f9ojvxpjFgHnlbLqQWvtu6f7+fEizH+HWzh5a8nV1tptxpjGwEJjzLpgphrTTrbtwN+ASbgfr0m4S1l3Vlx00RPOPjfGPAgcBV4v42Picp/LiYwx9YB/A2OstftKrF6Fa+rPDfaz+g/QuqJjjJIqewwH+z32BcaXsroy7/PjWGutMSZit/iedmJire35A962DWhRrNw8uKy4bFyTX/XgX1el1YkZ5f07GGOqAwOAzif5jG3B153GmHdwzeMxf4KHewwYY14A3i9lVTjHQ8wJY5/fAfwCuNYGL7iW8hlxuc9LEc4+LKqTETwfzsKd53HPGFMDl5S8bq2dU3J98UTFWjvPGDPdGNPQWhv3z1MJ4xiOy/M7TL2BVdbazJIrKvM+D8o0xjSx1m4PXprbWUqdbbi+NkWa4/qcnpRfl3LmAkODvfQvwGWR/1e8QvCH/BPg5uCi4UA8t8D0BNZZazNKW2mMqWuMSSyax3WeXFNa3XhS4lryTZS+TclAa+PuwqqJaxqdWxHxRYsxphfwR6CvtfZgGXUq0z4PZx/OxZ3H4M7r/5aVsMWTYD+ZfwLfWWufLKPOeUX9aYwxXXG/vXGflIV5DM8Fbg/endMNyCl2CSDeldkKXln3eTHFz+ey/n/+ELjOGFM/eBn/uuCyk4tyT96bcNeU8oBM4MNi6x7E9eIPAL2LLZ8HNA3OX4hLWFKBt4Ba0Yw3yv8WM4BRJZY1BeYV29avgtO3uMsBvscdge1+DfgG+Dp4IDcpue3Bch/c3QwbK8O2B4/ZrUBKcCq6G6XS7vPS9iHwCC45A6gdPI9Tg+f1hX7HHKHtvhp3qfLrYvu7DzCq6JwH7gnu469wnaGv8jvuCG17qcdwiW03wHPB4+Ibit2hGc8TUBeXaJxVbFml3Oe45Gs7kB/8P/0uXP+wj4ENwCKgQbBuF+DFYu+9M3jOpwIjwvk+jfwqIiIiMUMjv4qIiEjMUGIiIiIiMUOJiYiIiMQMJSYiIiISM5SYiIiISMxQYiIiUWGMOdsY8xu/4xCR+KLERESi5WzcE4VFRMKmxEREomUKcJExJsUY84TfwYhIfNAAayISFcEn7b5vrW3ncygiEkfUYiIiIiIxQ4mJiIiIxAwlJiISLfuBRL+DEJH4osRERKLCWpsNfG6MWaPOryISLnV+FRERkZihFhMRERGJGUpMREREJGYoMREREZGYocREREREYoYSExEREYkZSkxEREQkZigxERERkZihxERERERixv8HYY7MVcloyu0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.linspace(-10,10,100)\n",
    "sig=1/(1+np.exp(-a))\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot([-10,10],[0,0],\"k-\")\n",
    "plt.plot([-10,10],[0.5,0.5],\"k:\")\n",
    "plt.plot([-10,10],[1,1],\"k:\")\n",
    "plt.plot([0,0],[-1.1,1.1],\"k-\")\n",
    "plt.plot(a,sig,\"b-\",linewidth=2, label=r\"$\\sigma(t) = \\frac{1}{1 + e^{-t}}$\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.legend(loc=\"upper left\", fontsize=20)\n",
    "plt.axis([-10, 10, -0.1, 1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from scipy.special import expit\n",
    "\n",
    "# General a toy dataset:s it's just a straight line with some Gaussian noise:\n",
    "#xmin, xmax = -5, 5\n",
    "n_samples = 100\n",
    "np.random.seed(0)\n",
    "X = np.random.normal(size=n_samples)\n",
    "y = (X > 0).astype(np.float)\n",
    "X[X > 0] *= 4\n",
    "X += .3 * np.random.normal(size=n_samples)\n",
    "\n",
    "X = X[:, np.newaxis]\n",
    "\n",
    "# Fit the classifier\n",
    "clf = linear_model.LogisticRegression(C=1e5, solver='lbfgs')\n",
    "clf.fit(X, y)\n",
    "\n",
    "# and plot the result\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "\n",
    "X_test = np.linspace(-10, 10, 300)\n",
    "\n",
    "loss = expit(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "plt.plot(X_test, loss, color='red', linewidth=3)\n",
    "\n",
    "\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')\n",
    "plt.ylim(-1.25, 1.25)\n",
    "plt.xlim(-10, 10)\n",
    "plt.legend(('Logistic Regression Model'))\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a Machine Learning algorithm which is used for the classification problems, it is a predictive analysis algorithm and based on the concept of probability. Note that the probability prediction must be transformed into a binary values (0 or 1) in order to actually make a probability prediction. More on this later when we talk about making predictions.\n",
    "\n",
    "Logistic regression is a linear method, but the predictions are transformed using the logistic function. The impact of this is that we can no longer understand the predictions as a linear combination of the inputs as we can with linear regression.\n",
    "\n",
    "The Overall_rating, which is also our target outcome values, is a discrete numerical variables. Our prediction outcome is not continuous so we cannot apply regression models. We applied PCA because the original dataset after cleanning still remained 27 columns, which meant 27 dimensions. Human can usually visualize a 3 dimension graphs. We need to filter the most valuable features and reduce the dimensions with PCA by calculating the variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
