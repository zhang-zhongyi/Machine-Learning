{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Predictive Analytics    \n",
    "# Assignment 4     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Troy Zhongyi Zhang     \n",
    "Netid: zhongyiz@uchicago.edu      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('default of credit card clients.xls')\n",
    "df=df.drop(df.columns[[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df.columns[0]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - (c) and (d)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.model_selection as cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.iloc[:,23]\n",
    "X = df.iloc[:,1:22]\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest Classifier - Base Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhongyizhang/env/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2-(a) & 2-(b)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.9, 0.1],\n",
       "       ...,\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2-(b)\n",
    "prob1 = rnd_clf.predict_proba(X_test) \n",
    "prob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6597,  443],\n",
       "       [1327,  633]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2-(c)\n",
    "from sklearn import metrics\n",
    "rnd_matrix1 = metrics.confusion_matrix(y_test, y_pred_rf)\n",
    "rnd_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Default Payment 1       0.83      0.94      0.88      7040\n",
      "Default Payment 2       0.59      0.32      0.42      1960\n",
      "\n",
      "         accuracy                           0.80      9000\n",
      "        macro avg       0.71      0.63      0.65      9000\n",
      "     weighted avg       0.78      0.80      0.78      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Default Payment 1', 'Default Payment 2']\n",
    "print(\"\", classification_report(y_test, y_pred_rf, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7089591184485158\n"
     ]
    }
   ],
   "source": [
    "#2-(d)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "rnd_probs = rnd_clf.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, rnd_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-(e) For training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf_train = rnd_clf.predict(X_train)\n",
    "y_pred_rf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53333333, 0.46666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9       , 0.1       ],\n",
       "       ...,\n",
       "       [1.        , 0.        ],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.5       , 0.5       ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob12 = rnd_clf.predict_proba(X_train) \n",
    "prob12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16264,    60],\n",
       "       [  470,  4206]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_matrix2 = metrics.confusion_matrix(y_train, y_pred_rf_train)\n",
    "rnd_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Default Payment 1       0.97      1.00      0.98     16324\n",
      "Default Payment 2       0.99      0.90      0.94      4676\n",
      "\n",
      "         accuracy                           0.97     21000\n",
      "        macro avg       0.98      0.95      0.96     21000\n",
      "     weighted avg       0.98      0.97      0.97     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Default Payment 1', 'Default Payment 2']\n",
    "print(\"\", classification_report(y_train, y_pred_rf_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997941872232711\n"
     ]
    }
   ],
   "source": [
    "rnd_probs_train = rnd_clf.predict_proba(X_train)[:,1]\n",
    "print(roc_auc_score(y_train, rnd_probs_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-(e)     \n",
    "The training set accuracy score is 99.79%, but the testing set accuracy score is only 70.90%. The training set RMSE is much smaller than the testing set RMSE. This model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest Classifier - Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-(a) & 3-(c) for prediction class\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_estimators':[50,100,500],\n",
    "              'max_features':[2,4,6],\n",
    "              'max_depth':[6,8,10,12],\n",
    "              'random_state':[0,42]}\n",
    "\n",
    "rf_obj=RandomForestClassifier()\n",
    "\n",
    "rf_Grid = GridSearchCV(rf_obj, param_grid, cv = 5, scoring = 'roc_auc',refit = True, n_jobs=-1, verbose = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3-(c) for prediction class\n",
    "rf_Grid.fit(X_train, y_train)\n",
    "y_pred_rf_grid = rf_Grid.predict(X_test)\n",
    "y_pred_rf_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7694212010088126\n"
     ]
    }
   ],
   "source": [
    "rnd_probs_grid = rf_Grid.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, rnd_probs_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'max_features': 2, 'n_estimators': 500, 'random_state': 42}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3-(b)\n",
    "rf_Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features=2, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3-(b)\n",
    "rf_Grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7775348235048448"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                                  max_depth=10, max_features=2, max_leaf_nodes=None,\n",
    "                                  min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                  min_samples_leaf=1, min_samples_split=2,\n",
    "                                  min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "                                  n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
    "                                  warm_start=False)\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_best = best_clf.predict(X_test)\n",
    "y_pred_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84703202, 0.15296798],\n",
       "       [0.90705566, 0.09294434],\n",
       "       [0.89857752, 0.10142248],\n",
       "       ...,\n",
       "       [0.86690204, 0.13309796],\n",
       "       [0.90203603, 0.09796397],\n",
       "       [0.91643585, 0.08356415]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3-(c) for predict_proba()\n",
    "prob2 = best_clf.predict_proba(X_test) \n",
    "prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6718,  322],\n",
       "       [1344,  616]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3-(d)\n",
    "rnd_matrix_best = metrics.confusion_matrix(y_test, y_pred_best)\n",
    "rnd_matrix_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Default Payment 1       0.83      0.95      0.89      7040\n",
      "Default Payment 2       0.66      0.31      0.43      1960\n",
      "\n",
      "         accuracy                           0.81      9000\n",
      "        macro avg       0.75      0.63      0.66      9000\n",
      "     weighted avg       0.79      0.81      0.79      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Default Payment 1', 'Default Payment 2']\n",
    "print(\"\", classification_report(y_test, y_pred_best, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7694212010088126\n"
     ]
    }
   ],
   "source": [
    "#3-(e)\n",
    "rnd_probs_best = best_clf.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, rnd_probs_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-(f) For training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_best_train = best_clf.predict(X_train)\n",
    "y_pred_best_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69650515, 0.30349485],\n",
       "       [0.9053    , 0.0947    ],\n",
       "       [0.41140012, 0.58859988],\n",
       "       ...,\n",
       "       [0.70860525, 0.29139475],\n",
       "       [0.70819115, 0.29180885],\n",
       "       [0.78885772, 0.21114228]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_best_train = best_clf.predict_proba(X_train) \n",
    "prob_best_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15943,   381],\n",
       "       [ 2721,  1955]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_matrix_best_train = metrics.confusion_matrix(y_train, y_pred_best_train)\n",
    "rnd_matrix_best_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Default Payment 1       0.85      0.98      0.91     16324\n",
      "Default Payment 2       0.84      0.42      0.56      4676\n",
      "\n",
      "         accuracy                           0.85     21000\n",
      "        macro avg       0.85      0.70      0.73     21000\n",
      "     weighted avg       0.85      0.85      0.83     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Default Payment 1', 'Default Payment 2']\n",
    "print(\"\", classification_report(y_train, y_pred_best_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8545774258183672\n"
     ]
    }
   ],
   "source": [
    "rnd_probs_best_train = best_clf.predict_proba(X_train)[:,1]\n",
    "print(roc_auc_score(y_train, rnd_probs_best_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-(f)     \n",
    "    The testing set accuracy score is 76.94%, and the training set accuracy score is 85.46%. The training set RMSE is smaller than the testing set RMSE. This model is still overfitting, but this model from question 3 is much better than the previous model from question 2. The RMSE difference between training and testing sets is getting smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create a feature importance plot for your best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00568214 0.01151864 0.00719227 0.02768741 0.22185061 0.10943561\n",
      " 0.0779052  0.05858338 0.05286063 0.04365488 0.03589474 0.03440817\n",
      " 0.03234817 0.03247281 0.03121666 0.03133298 0.04763581 0.0382054\n",
      " 0.0364141  0.03324387 0.03045653]\n"
     ]
    }
   ],
   "source": [
    "print(best_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.bar(range(len(best_clf.feature_importances_)), best_clf.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(best_clf.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-(a) According to the feature importance plot, the top five features of this model are PAY_0, PAY_2, PAY_3, PAY_4, and PAY_5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX = 0.0056821361520653915\n",
      "EDUCATION = 0.01151864225514549\n",
      "MARRIAGE = 0.007192272649820701\n",
      "AGE = 0.0276874148952046\n",
      "PAY_0 = 0.22185060856486621\n",
      "PAY_2 = 0.10943561331288647\n",
      "PAY_3 = 0.0779052029646254\n",
      "PAY_4 = 0.05858338400037015\n",
      "PAY_5 = 0.052860629726516256\n",
      "PAY_6 = 0.043654884677863263\n",
      "BILL_AMT1 = 0.03589474087645829\n",
      "BILL_AMT2 = 0.034408166021321726\n",
      "BILL_AMT3 = 0.032348168330102844\n",
      "BILL_AMT4 = 0.03247280577030198\n",
      "BILL_AMT5 = 0.03121665607899434\n",
      "BILL_AMT6 = 0.03133297613418786\n",
      "PAY_AMT1 = 0.047635808787411985\n",
      "PAY_AMT2 = 0.03820540075468745\n",
      "PAY_AMT3 = 0.036414097418261224\n",
      "PAY_AMT4 = 0.03324386547433505\n",
      "PAY_AMT5 = 0.030456525154573474\n"
     ]
    }
   ],
   "source": [
    "for name, importance in zip(feature_names, best_clf.feature_importances_):\n",
    "    print(name, \"=\", importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SEX', 0.0056821361520653915]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[list(x) for x in zip(feature_names, best_clf.feature_importances_)]\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=dict(list(x) for x in zip(feature_names, best_clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEX'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEX': 0.0056821361520653915,\n",
       " 'EDUCATION': 0.01151864225514549,\n",
       " 'MARRIAGE': 0.007192272649820701,\n",
       " 'AGE': 0.0276874148952046,\n",
       " 'PAY_0': 0.22185060856486621,\n",
       " 'PAY_2': 0.10943561331288647,\n",
       " 'PAY_3': 0.0779052029646254,\n",
       " 'PAY_4': 0.05858338400037015,\n",
       " 'PAY_5': 0.052860629726516256,\n",
       " 'PAY_6': 0.043654884677863263,\n",
       " 'BILL_AMT1': 0.03589474087645829,\n",
       " 'BILL_AMT2': 0.034408166021321726,\n",
       " 'BILL_AMT3': 0.032348168330102844,\n",
       " 'BILL_AMT4': 0.03247280577030198,\n",
       " 'BILL_AMT5': 0.03121665607899434,\n",
       " 'BILL_AMT6': 0.03133297613418786,\n",
       " 'PAY_AMT1': 0.047635808787411985,\n",
       " 'PAY_AMT2': 0.03820540075468745,\n",
       " 'PAY_AMT3': 0.036414097418261224,\n",
       " 'PAY_AMT4': 0.03324386547433505,\n",
       " 'PAY_AMT5': 0.030456525154573474}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "b = OrderedDict(sorted(a.items(), key=itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('SEX', 0.0056821361520653915),\n",
       "             ('MARRIAGE', 0.007192272649820701),\n",
       "             ('EDUCATION', 0.01151864225514549),\n",
       "             ('AGE', 0.0276874148952046),\n",
       "             ('PAY_AMT5', 0.030456525154573474),\n",
       "             ('BILL_AMT5', 0.03121665607899434),\n",
       "             ('BILL_AMT6', 0.03133297613418786),\n",
       "             ('BILL_AMT3', 0.032348168330102844),\n",
       "             ('BILL_AMT4', 0.03247280577030198),\n",
       "             ('PAY_AMT4', 0.03324386547433505),\n",
       "             ('BILL_AMT2', 0.034408166021321726),\n",
       "             ('BILL_AMT1', 0.03589474087645829),\n",
       "             ('PAY_AMT3', 0.036414097418261224),\n",
       "             ('PAY_AMT2', 0.03820540075468745),\n",
       "             ('PAY_6', 0.043654884677863263),\n",
       "             ('PAY_AMT1', 0.047635808787411985),\n",
       "             ('PAY_5', 0.052860629726516256),\n",
       "             ('PAY_4', 0.05858338400037015),\n",
       "             ('PAY_3', 0.0779052029646254),\n",
       "             ('PAY_2', 0.10943561331288647),\n",
       "             ('PAY_0', 0.22185060856486621)])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-(a) I test my previous results here. According to the sorted rank, the top five features of this model are PAY_0, PAY_2, PAY_3, PAY_4, and PAY_5 (From high to low, the largest number is at the bottom of the above list. The number means the feature importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00568214, 0.01151864, 0.00719227, 0.02768741, 0.22185061,\n",
       "       0.10943561, 0.0779052 , 0.05858338, 0.05286063, 0.04365488,\n",
       "       0.03589474, 0.03440817, 0.03234817, 0.03247281, 0.03121666,\n",
       "       0.03133298, 0.04763581, 0.0382054 , 0.0364141 , 0.03324387,\n",
       "       0.03045653])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Creating a plot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(1, 21)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.hot,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit(best_clf.feature_importances_)\n",
    "\n",
    "cbar = plt.colorbar(ticks=[best_clf.feature_importances_.min(), best_clf.feature_importances_.max()])\n",
    "cbar.ax.set_yticklabels(['Not important', 'Very important'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conceptual Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What are the best parameters from the Grid Search in Question # 3? Does the Model from #3 outperform Model #2? Explain why.\n",
    "\n",
    "b) Overfitting is always a concern in ML problems. Does Model #3 overfit data more or less than Model #2? Explain why you think this is the case. \n",
    "\n",
    "c) The lecture notes describe the Gini Index which is the default criterion used for splitting in sklearn's version of RandomForestClassifier. How does the Gini Index work? (i.e. How is it used to build a top-performing model?). \n",
    "\n",
    "d) Describe how Random Forest is different from bagging & why this difference can yield improved results.\n",
    "\n",
    "e) Describe the importance of the max_depth parameter in Random Forest. Do not just provide a definition, rather think through how bias-variance tradeoff might be impacted by the max_depth parameter.\n",
    "\n",
    "f) In this homework we used k-fold cross-validation while determining the optimal hyperparameters for our Random Forest model. 1) Describe how k-fold cross-validation works. 2) What benefit do we gain by using k-fold cross-validation when tuning our Random Forest model versus only using the train-test split approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) The best model has following parameters: {'max_depth': 10, 'max_features': 2, 'n_estimators': 500, 'random_state': 42}.      \n",
    "By using rf_Grid.best_estimator_ to go over more details, the best model has parameters:     \n",
    "\n",
    "(bootstrap=True, class_weight=None, criterion='gini',      \n",
    "max_depth=10, max_features=2, max_leaf_nodes=None,      \n",
    "min_impurity_decrease=0.0, min_impurity_split=None,      \n",
    "min_samples_leaf=1, min_samples_split=2,           \n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,        \n",
    "n_jobs=None, oob_score=False, random_state=42, verbose=0,       \n",
    "warm_start=False)        \n",
    "                       \n",
    "The model in question 3 is better than model 2. Without specifying parameters, the model only gave the default parameters. However, we utilize our models by finding the best parameters in our given range. With correct parameters, the training set RMSE is much closer to the testing set RMSE (14% and 23%) than the model from question 2 (0% for training and 30% for testing). This means the new model in question 3 is still overfitting but much better than model from Q2. The previous model in question 2 has a huge error difference between training and testing sets. The model in question 2 has almost no error for training set but nearly 30% errors for testing set. This model is very overfitting. The model in question 3 is much better than the model in question 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model. The problem is that these concepts do not apply to new data and negatively impact the models ability to generalize. Overfitting means high variance and low bias, and underfitting means high bias and low variance. Overfitting usually fit the training set so well that if data coming outside from testing set try to use this model, the accuracy will be very low. The overfitting waste abundant computation resources and honestly, not useful in real day work since it cannot tolerate new data coming in.    \n",
    "\n",
    "Like I mentioned in part(a), the new model from question 3 is much better than the previous model from question 2. The difference between the training set RMSE and the testing set RMSE is getting smaller in Q3. This means the model in Q3 is better than the model in Q2. However, there is a huge difference between the training set error and testing set error for the previous model in question 2. The training set accuracy is almost 100%, but the testing set accuracy is just a little bit above 70%. The model from Q2 is overfitting because this model doesn't work for testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) The Gini Index is calculated by subtracting the sum of the squared probabilities of each class from one. It favors larger partitions. Information gain multiplies the probability of the class times the log (base=2) of that class probability. Information gain favors smaller partitions with many distinct values. Gini index or Gini impurity measures the degree or probability of a particular variable being wrongly classified when it is randomly chosen. I also need to mention a little about Impurity. If all the elements belong to a single class, then it can be called pure. The degree of Gini index varies between 0 and 1, where 0 denotes that all elements belong to a certain class or if there exists only one class, and 1 denotes that the elements are randomly distributed across various classes. A Gini Index of 0.5 denotes equally distributed elements into some classes. Gini Index, unlike information gain, isn’t computationally intensive as it doesn’t involve the logarithm function used to calculate entropy in information gain, which is why Gini Index is preferred over Information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) By definition, in random forests, only a subset of features are selected at random out of the total and the best split feature from the subset is used to split each node in a tree, unlike in bagging where all features are considered for splitting a node. Bagging (or Bootstrap Aggregating), uses a different random subset of the original dataset for each model in the ensemble. Specifically, BigML uses by default a sampling rate of 100% with replacement for each model, this means that some of the original instances will be repeated and others left out. Random Decision Forests extend this technique by only considering a random subset of the input fields at each split. Generally, Random Decision Forests are the most powerful type of ensemble. For datasets with many noisy fields I may need to adjust a Random Decision Forest's \"random candidates\" parameter for good results. Bagging, however, does not have this parameter and may occasionally give better out-of-the-box performance. Ensemble learning always improves machine learning results. Random forests will split relatively random without giving stable performances. Sometimes the bagging is more stable compared with random forest. The two models work together can give a better, more reasonable, and more logical result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Max_depth represents the depth of each tree in the forest. The deeper the tree, the more splits it has and it captures more information about the data. We fit each decision tree with depths ranging from 1 to 32 and plot the training and test errors.    \n",
    "\n",
    "As large the max_depth value goes, the trees perfectly predicts all of the train data. However, it fails to generalize the findings for new data. In this case, the large max_depth value could fits the training set well, but it will cause OVERFITTING. The max_depth will not work well on new coming data from testing sets. As variance goes higher, the bias will always be lower. This is the trade-off. If I fit the training set too accurate, the tolerance performance for new data will always decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f)          \n",
    "1) K-Fold CV is where a given data set is split into a K number of sections/folds where each fold is used as a testing set at some point. For example, if I have 5-Fold cross validation(K=5), the data set is split into 5 folds. In the first iteration, the first fold is used to test the model and the rest are used to train the model. In the second iteration, 2nd fold is used as the testing set while the rest serve as the training set. This process is repeated until each fold of the 5 folds have been used as the testing set.      \n",
    "\n",
    "2) 𝑘-fold cross validation can help me to measure the stability of the predictions for the same test case with respect to slight changes in the training data. Aggregation helps to improve this stability. If I set k=10, I split the data into 10 partitions, and run the classifier for 10 times. In each time, I choose different partition as validation set and training set. In the first time, I choose partition 1 as validation set, the remaining are training set. In the second time, I choose partition 2 as validation set, and so on. After running 10 times, I average their results. Since random forest always split randomly and the prediction result can vary hugely. The k-fold cross validation averaging the results can always give me a more stable performance for my model. The core benefit is improving the stablility by aggregating the k-fold CV and Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
